{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"img/logo.png\" width=\"500\">\n",
    "\n",
    "\n",
    "# Análisis de Regresión (2021-3)\n",
    "## Especialización en Estadística Aplicada\n",
    "#### Prof. [Sébastien Lozano Forero](https://www.linkedin.com/in/sebastienlozanoforero/) (slozanof@libertadores.edu.co)\n",
    "\n",
    "## <font color='red'> Introducción a la Regresión Lineal Múltiple</font>\n",
    "\n",
    "### Tabla de contenidos\n",
    "\n",
    "* [Modelo de Regresión Lineal Múltiple](#modelo)\n",
    "* [Resultados Generales](#resultados)\n",
    "* [Supuestos](#supuestos)\n",
    "* [Validación de Supuestos](#validacion) \n",
    "* [Influencia y Diagnóstico](#influencia)\n",
    "* [Ejemplo](#ejemplo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regresión Lineal Múltiple <a class=\"anchor\" id=\"modelo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"img/multiple.png\" width=\"400\">\n",
    "\n",
    "El modelo de regresión lineal simple da cuenta de la relación **lineal** y **causal** entre las variables $X_1,X_2,\\cdots X_n,  Y$ ($X_1,X_2,\\cdots X_n$ causan a $Y$).\n",
    "\n",
    "Continuamos con el estudio del análisis de regresión considerando, ahora, las situaciones en las que intervienen dos o más variables predictoras o independientes. Este estudio, al que se le conoce como **análisis de regresión múltiple**, permite tomar más factores en consideración y obtener estimaciones mejores que las que son posibles con la regresión lineal simple.\n",
    "\n",
    "El análisis de regresión múltiple estudia la relación de una variable respuesta con dos o más variables predictoras. Para denotar el número de variables predictoras independientes se suele usar $p$. A la ecuación que describe cómo está relacionada la variable respuesta $Y$ con las variables predictoras $X_1$, $X_2$, $\\cdots$, $X_p$ se le conoce como **modelo de regresión múltiple** y se escribe de la siguiente forma\n",
    "$$\n",
    "Y=\\beta_0 +\\beta_1X_1+\\beta_2X_2+\\cdots+\\beta_pX_p+\\epsilon \\tag{1}\n",
    "$$\n",
    "\n",
    "Donde: \n",
    "- $\\beta_0, \\beta_1, \\cdots, \\beta_p$ son parámetros poblacionales a ser estimados.\n",
    "- $\\epsilon$ representa un error aleatorio (Nuestra incapacidad para dar cuenta de la realidad tal cuál es)\n",
    "- $Y$ representa la *variable respuesta*\n",
    "- $X_1,\\cdots X_p$ representan las *variables predictoras*\n",
    "\n",
    "<img style=\"float: right;\" src=\"img/red.png\" width=\"400\">\n",
    "\n",
    "Si se conocieran los valores de $\\beta_0$, $\\beta_1$, $\\beta_2$, $\\cdots$, $\\beta_p$, se podría usar la ecuación $(2)$ para calcular la media de las $Y$ para valores dados de $X_1$, $X_2$, $\\cdots$, $X_p$. Desafortudamente, los valores de estos parámetros no suelen conocerse, es necesario estimarlos a partir de datos muestrales. \n",
    "\n",
    "Para calcular los valores de los estadísticos muestrales $\\hat{\\beta}_0$, $\\hat{\\beta}_1$, $\\hat{\\beta}_2$, $\\cdots$, $\\hat{\\beta}_p$, que se usan como estimadores puntuales de los parámetros $\\beta_0$, $\\beta_1$, $\\beta_2$, $\\cdots$, $\\beta_p$ se emplea una muestra aleatoria simple. Con los estadísticos muestrales se obtiene la siguiente **ecuación de regresión múltiple estimada**\n",
    "\n",
    "$$\n",
    "\\widehat{Y}=\\hat{\\beta}_0+\\hat{\\beta}_1X_1+\\hat{\\beta}_2X_2+\\cdots+\\hat{\\beta}_pX_p\n",
    "$$\n",
    "donde $\\hat{\\beta}_0$, $\\hat{\\beta}_1$, $\\hat{\\beta}_2$, $\\cdots$, $\\hat{\\beta}_p$ son las estimaciones de $\\beta_0$, $\\beta_1$, $\\beta_2$, $\\cdots$, $\\beta_p$ y $\\widehat{Y}$ es el valor estimado de la media de $Y$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supuestos <a class=\"anchor\" id=\"supuestos\"></a>\n",
    "\n",
    "El modelo de regresión lineal múltiple, como tantísimos otros (casi absolutamente todos) modelos estadísticos, deberá cumplir una serie de supuestos que permitan concluir que el mismo es una buena versión simplificada de la información y, por tanto, tiene sentido usarlo para establecer dichas relaciones ded causación. De esta manera, los principales supuestos para el modelo de regresión lineal simple $y_t = \\beta_0 + \\beta_1x_{1t}+\\beta_2x_{2t}+\\cdots +\\beta_kx_{kt} + \\epsilon_t$ son \n",
    "- [S0] El modelo es una buena representación de la realidad (tiene sentido)\n",
    "- [S1] $E(\\epsilon_t)=0$\n",
    "- [S2] $Cov(\\epsilon_t ,\\epsilon_s) = 0$ siempre que $i\\neq j$\n",
    "- [S3] $Var(\\epsilon_t) =\\sigma_t^2 =\\sigma^2$ (Homoscedasticidad)\n",
    "- [S4] $X$ es de rango completo\n",
    "- [S5] [opcional pero recomendado] $y_t \\sim N(\\mu_t, \\sigma^2)$\n",
    "\n",
    "Típicamente, en todos los modelos estadísticos, la forma e validar los supuestos es a través de los residuos (Hay que tener presente que los errores son variables aleatorios, mientras que los residuos son realizaciones de tales variables). De esta manera se definen los residuos como $r_t= y_t-\\hat{y}_t$, donde $\\hat{y}_t$ es el valor predicho para $y_t$ por el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Generales <a class=\"anchor\" id=\"modelo\"></a>\n",
    "\n",
    "<img style=\"float: right;\" src=\"img/matrix.gif\" width=\"400\">\n",
    "\n",
    "Podemos escribir el modelo de regresión muestral correspondiente al modelo $(1)$ como\n",
    "$$\n",
    "y_i=\\beta_0+\\beta_1x_{i1}+\\beta_2x_{i2}+\\cdots+\\beta_px_{ip}+\\epsilon_i, \\ \\ i=1,2,\\cdots,n\n",
    "$$\n",
    "\t\n",
    "En notación matricial, este modelo de regresión muestral se representa como\n",
    "$$\n",
    "\\mathbf{Y}=\\mathbf{X\\beta}+\\mathbf{\\epsilon}\n",
    "$$\n",
    "donde\n",
    "$$\n",
    "\\begin{array}{cccc}\n",
    "\\mathbf{Y}=\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{pmatrix}, & \\mathbf{X}=\\begin{pmatrix}\n",
    "1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\\n",
    "1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n",
    "\\vdots & \\vdots & \\vdots & & \\vdots \\\\\n",
    "1 & x_{n1} & x_{n2} & \\cdots & x_{np} \\\\\n",
    "\\end{pmatrix}, \n",
    "\\mathbf{\\beta}=\\begin{pmatrix}\n",
    "\\beta_0 \\\\\n",
    "\\beta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\beta_p\n",
    "\\end{pmatrix}, & \\mathbf{\\epsilon}=\\begin{pmatrix}\n",
    "\\epsilon_1 \\\\\n",
    "\\epsilon_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\epsilon_n\n",
    "\\end{pmatrix}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Deseamos encontrar el vector de estimadores de mínimos cuadrados, $\\mathbf{\\beta}$, que minimiza\n",
    "\n",
    "$$\n",
    "Q(\\mathbf{\\beta})=\\sum r_i^2=(\\mathbf{Y-X\\beta})'(\\mathbf{Y-X\\beta})\n",
    "$$\n",
    "Podemos probar que el estimador de mínimos cuadrados de $\\mathbf{\\beta}$ es\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{\\beta}}=(\\mathbf{X'X})^{-1}\\mathbf{X'Y}\n",
    "$$\n",
    "siempre que la matriz inversa $(\\mathbf{X'X})^{-1}$ exista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medidas de bondad de ajuste\n",
    "\n",
    "<img style=\"float: right;\" src=\"img/decision.jpg\" width=\"350\">\n",
    "\n",
    "##### R cuadrado ajustado\n",
    "\n",
    "Muchos analistas prefieren ajustar $R^2$ al número de variables independientes para evitar sobreestimar el efecto que tiene agregar una variable independiente sobre la cantidad de la variabilidad explicada por la ecuación de regresión estimada. Siendo $n$ el número de observaciones y $p$ el número de variables independientes, el coeficiente de determinación ajustado se calcula como sigue.\n",
    "$$\n",
    "R_{adj}^2=1-(1-R^2)\\frac{n-1}{n-k-1}\n",
    "$$\n",
    "\n",
    "##### Criterios de selección\n",
    "El AIC se define como:\n",
    "\n",
    "$$\n",
    "AIC = - 2\\text{logLik} + pk,\n",
    "$$\n",
    "\n",
    "donde  logLik corresponde al valor de log-verosimilitud del modelo para el vector de parámetros $\\beta$, $p$ es un valor de penalización por el exceso de parámetros y $k$ corresponde al número de parámetros del modelo.\n",
    "\n",
    "Se debe recordar siempre que:\n",
    "\n",
    "- El mejor modelo es aquel que  logLik alto\n",
    "- El mejor modelo es aquel que  AIC bajo\n",
    " \n",
    "Cuando el valor de penalización  $k=log(n)$, entonces el AIC se llama BIC (Schwarz’s Bayesian criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pruebas de hipótesis\n",
    "\n",
    "<img style=\"float: right;\" src=\"img/hipotesis.jpg\" width=\"400\">\n",
    "\n",
    "En general, va a ser de nuestro interés obtener evidencia empírica de la validez estadística de los parámetros que indexan el modelo. Para esto, se hace necesario introducir pruebas de hipótesis para los parámetros. \n",
    "\n",
    "Considere, la prueba de las hipótesis para $\\beta_i$:\n",
    "\\begin{align*}\n",
    "H_0: \\, \\beta_i &=\\beta_{i0} (\\beta_{i0} \\text{conocido})\\\\\n",
    "H_1: \\, \\beta_i &\\neq \\beta_{i0}\n",
    "\\end{align*}\n",
    "\n",
    "que tiene como estadístico de prueba:\n",
    "\t\n",
    "$$\n",
    "T_{Est}=\\frac{\\hat{\\beta}_1-\\beta_{10}}{s\\{\\hat{\\beta}_1\\}} \\sim t_{(n-p-1)}\n",
    "$$\n",
    "\t\n",
    "y la regla de decisión para el nivel de significancia $\\alpha$ es $p$-valor $<\\alpha$ donde $p$-valor $= 2P(T>|T_{Est}|)$ con $T\\sim t_{(n-p-1)}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación de Supuestos <a class=\"anchor\" id=\"validacion\"></a>\n",
    "\n",
    "Una vez planteados los supuestos, es necesario ver cómo se validarán en ejemplos prácticos. En esta situación, simularemos los datos para poder validar cada uno de los supuestos.\n",
    "\n",
    "<img style=\"float: center;\" src=\"img/residuos.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "x <- rnorm(250, mean=10, sd=5) # Distribución normal\n",
    "z <- rexp(250, rate=0.1) #Distribución exponencial\n",
    "w <- rbinom(250, 100,0.25) #Distribución Binomial\n",
    "y <- 58 + 1.8*x+4.3*z +5*w + rnorm(250, sd=3) \n",
    "head(data.frame(x=x,y=y,z=z,w=w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al haber simulado el modelo $y_t = 58 + 1.8x_t+4.3z_t+5w_t+\\epsilon_t$ ($\\beta_0=58, \\beta_1=1.8, \\beta_2=4.3$ y $\\beta_3=5$), debe ser natural que el modelo ajustado sea similar, veamos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajuste <- lm(y ~ x + z + w) #tarea: glm\n",
    "summary(ajuste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ww<- rnorm(250, mean=15, sd=2)\n",
    "ajuste2 <- lm(y~x+z+ww)\n",
    "summary(ajuste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=12, repr.plot.height=12)\n",
    "par(mfrow=c(2,2))\n",
    "plot(ajuste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [S0] El modelo es una buena representación de la realidad (tiene sentido)\n",
    "\n",
    "El día que exista una prueba de hipótesis que verifique este supuesto, todos todos los que hagamos estadística, nos quedaremos sin trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [S1] $E(\\epsilon_t)=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos <- residuals(ajuste)\n",
    "mean(residuos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [S2] $Cov(\\epsilon_t ,\\epsilon_s) = 0$ siempre que $i\\neq j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"lmtest\")\n",
    "library(lmtest) # ver https://en.wikipedia.org/wiki/Durbin%E2%80%93Watson_statistic\n",
    "dwtest(ajuste) # H0: No hay autocorrelación en los errores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [S3] $Var(\\epsilon_t) =\\sigma_t^2 =\\sigma^2$ (Homoscedasticidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(lmtest) #https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test\n",
    "bptest(ajuste) #H0: Homoscedasticidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [S4] $X$ es de rango completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(data.frame(x=x, z=z, w=w)) #Matriz de correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# install.packages(\"car\")\n",
    "library(car)\n",
    "vif(ajuste) #Autovalores de la matriz de correlaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [S5] [opcional pero recomendado] $y_t \\sim N(\\mu_t, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"tseries\")\n",
    "library(tseries)#https://en.wikipedia.org/wiki/Jarque%E2%80%93Bera_test\n",
    "jarque.bera.test(residuos) #H0: Normalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influencia y Diagnósitico <a class=\"anchor\" id=\"influencia\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problemas con los errores\n",
    "\n",
    "<img style=\"float: right;\" src=\"img/influence.png\" width=\"400\">\n",
    "\n",
    "##### Posibles problemas y controles de diagnóstico\n",
    "\n",
    "- Es posible que los errores no se distribuyan normalmente o que no tengan el mismo varianza: qqnorm puede ayudar con esto. Puede que esto no sea demasiado importante en muestras grandes.\n",
    "\n",
    "- La varianza puede no ser constante. También se puede abordar en una gráfica de $X$ frente a $\\epsilon$ u otra tendencia indica\n",
    "    varianza no constante.\n",
    "\n",
    "- Observaciones influyentes. Qué puntos \"afectan\" la línea de regresión lo mas?\n",
    "\n",
    "- Valores atípicos: puntos en los que el modelo realmente no encaja. Posiblemente errores en la transcripción de datos, errores de laboratorio, ¿quién sabe? Debiera ser reconocido y (con suerte) explicado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tipos de residuos\n",
    "\n",
    "<img style=\"float: right;\" src=\"img/ponderacion.png\" width=\"400\">\n",
    "\n",
    "- Residuos ordinarios: $ \\epsilon_i = Y_i - \\widehat{Y} _i $. Estos miden el\n",
    "    desviación del valor predicho del valor observado, pero su\n",
    "    la distribución depende de una escala desconocida, $ \\ sigma $.\n",
    "\n",
    "- Residuos estudiados internamente (`rstandard` en R):\n",
    "    $$ r_i = \\epsilon_i / SE (\\epsilon_i) = \\frac{\\epsilon_i} {\\widehat{\\sigma}\\sqrt{1-H_{ii}}} $$\n",
    "    \n",
    "- Arriba, $ H $ es la matriz de \"sombrero\" $ H = X (X ^ TX)^{-1}X^T $. Estos son casi $ t $ distribuidos, excepto \n",
    "    $ \\widehat{\\sigma} $ que depende de $ \\epsilon_t $.\n",
    "    \n",
    "- Residuos estudiados externamente (`rstudent` en R):\n",
    "$$ t_i = \\frac{\\epsilon_i}{\\widehat {\\sigma_{(i)}} \\sqrt {1-H_ {ii}}}\\sim t_{n-p-2}. $$ Estos son exactamente $ t $ distribuidos, por lo que conocemos su distribución y puede usarlos para pruebas, si lo desea.\n",
    "    \n",
    "- La cantidad $ \\hat {\\sigma}^2_{(i)} $ es el MSE del modelo ajustado a todos los datos excepto al caso $ i $ (es decir, tiene $ n-1 $ observaciones y $ p $ características).\n",
    "\n",
    "- Numéricamente, estos residuos están altamente correlacionados, como era de esperar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=4)\n",
    "plot(resid(ajuste), rstudent(ajuste), bg='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=4)\n",
    "plot(rstandard(ajuste), rstudent(ajuste), bg='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Influencia de una observación\n",
    "\n",
    "Otras gráficas proporcionan una evaluación de la \"influencia\" de cada observación. Por lo general, esto se hace eliminando un caso completo $ (y_i, x_i) $ del conjunto de datos y reacondicionamiento del modelo.\n",
    "\n",
    "- En esta configuración, $ \\cdot_{(i)} $ indica que la observación $ i $ -ésima  no se utiliza para ajustar el modelo.\n",
    "\n",
    "- Por ejemplo: $ \\widehat{Y}_{j (i)} $ es la función de regresión evaluados en los predictores de observación $ j $ -ésimo PERO los coeficientes $ (\\widehat {\\beta}_{0(i)}, \\dots, \\widehat {\\beta}_{p(i)}) $ estaban en forma después de eliminar $ i $ -ésimo caso de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Idea: si $\\widehat{Y}_{j(i)} $ es muy diferente de $\\widehat{Y}_j$ (usando todos los datos) entonces $ i $ es un punto influyente, al menos para estimando la función de regresión en $(X_{1,j},\\dots, X_{p,j}) $.\n",
    "    \n",
    "- También podría ver la diferencia entre $\\widehat{Y}_{i(i)}-\\widehat{Y}_i$, o cualquier otra medida.\n",
    "    \n",
    "- Hay varias medidas estándar de influencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DFFITS\n",
    "\n",
    "$$ DFFITS_i = \\frac{\\widehat{Y}_i - \\widehat{Y}_{i(i)}} {\\widehat {\\sigma}_{(i)}\\sqrt {H_{ii}}} $$\n",
    "\n",
    "- Esta cantidad mide cuánto cambia la función de regresión en  el $i$-ésimo caso / observación cuando el $i$ -ésimo caso / observación es eliminada.\n",
    "\n",
    "- Para conjuntos de datos pequeños / medianos: el valor de 1 o más es \"sospechoso\" (RABE). Para un conjunto de datos grande: valor de $ 2\\sqrt{(p + 1)/n} $.\n",
    "    \n",
    "- R tiene sus propias reglas estándar similares a las anteriores para marcar una observación tan influyente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*sqrt(4/250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dffits(ajuste), pch=23, bg='orange', cex=0.5, ylab=\"DFFITS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distancia de Cook\n",
    "\n",
    "La distancia de Cook mide cuánto toda la función de regresión cambia cuando se elimina el caso $i$-ésimo.\n",
    "\n",
    "$$D_i = \\frac{\\sum_{j=1}^n(\\widehat{Y}_j - \\widehat{Y}_{j(i)})^2}{(p+1) \\, \\widehat{\\sigma}^2}$$\n",
    "\n",
    "- Debe ser comparable a $ F_ {p + 1, n-p-1} $: si el \"$ p $ -valor\" de $ D_i $\n",
    "    es del 50 por ciento o más, entonces el caso de $ i $ -ésimo es probablemente influyente:\n",
    "    investigar más a fondo. (RABE)\n",
    "    \n",
    "- Nuevamente, `R` tiene sus propias reglas similares a las anteriores para marcar una observación\n",
    "tan influyente.\n",
    "\n",
    "- ¿Qué hacer después de la investigación? No es una respuesta fácil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(cooks.distance(ajuste), pch=23, bg='orange', cex=0.5, ylab=\"Cook's distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DFBETAS\n",
    "\n",
    "Esta cantidad mide cuánto cambian los coeficientes cuando el $i$-ésimo caso se elimina.\n",
    "\n",
    "\n",
    "$$DFBETAS_{j(i)} = \\frac{\\widehat{\\beta}_j - \\widehat{\\beta}_{j(i)}}{\\sqrt{\\widehat{\\sigma}^2_{(i)} (X^TX)^{-1}_{jj}}}.$$\n",
    "\n",
    "   \n",
    "Para conjuntos de datos pequeños / medianos: el valor absoluto de 1 o mayor es \"suspicaz\". Para un conjunto de datos grande: valor absoluto de $ 2/\\sqrt{n} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2/sqrt(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dfbetas(ajuste)[,'x'], pch=23, bg='orange', cex=0.5, ylab=\"DFBETA (x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dfbetas(ajuste)[,'z'], pch=23, bg='orange', cex=0.5, ylab=\"DFBETA (z)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Valores atípicos\n",
    "\n",
    "<img style=\"float: right;\" src=\"diferente.jpg\" width=\"400\">\n",
    "\n",
    "La definición esencial de un *valor atípico* es un par de observación $(Y, X_1,\\dots, X_p) $ que no sigue el modelo, mientras que la mayoría de las otras observaciones parecen seguir el modelo.\n",
    "\n",
    "- Valor atípico en * predictores *: los valores de $ X $ de la observación pueden estar fuera de la \"nube\" de otros valores $ X $. Esto significa que puede ser extrapolando su modelo de manera inapropiada. Los valores $ H_{ii} $ pueden ser se utiliza para medir qué tan \"atípicos\" son los valores de $ X $.\n",
    "\n",
    "- Valor atípico en *respuesta*: el valor $ Y $ de la observación puede ser muy lejos del modelo ajustado. Si los residuales studentizados son grandes: la observación puede ser un valor atípico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Valores atípicos en  $ X $\n",
    "\n",
    "Una forma de detectar valores atípicos en los *predictores*, además de observar los valores reales en sí mismos, es a través de sus valores de apalancamiento, definidos por\n",
    "$$\n",
    "\\text{leverage}_i = H_{ii} = (X (X ^ TX) ^ {- 1} X ^ T) _ {ii}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(hatvalues(ajuste), pch=23, bg='orange', cex=0.5, ylab='Hat values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí, parece terrible hacer estudios de influencia y diagnóstico. La matemática es compleja y ésta es un área todavía en estudio, por lo tanto, las cosas pueden cambiar en los próximos años. Sin embargo, no debe generar preocupación el uso de toda esta información para determinar cuáles puntos deben ser influyentes o atípicos de forma desmedida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(influence.measures(ajuste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo <a class=\"anchor\" id=\"modelo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejemplo retomaremos el conjunto de datos estudiado en la clase 3. Esta es la base de datos que da cuenta de la distribución de pagos en una empresa ¿Hay discriminación por género? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base <- read.csv('glassdoordata.csv')\n",
    "head(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables son \n",
    "<img style=\"float: right;\" src=\"img/genero.png\" width=\"400\">\n",
    "\n",
    "- **job title**: Título del trabajo (e.g. “Graphic Designer”, “Software Engineer”, etc);\n",
    "- **gender**: Hombre o mujer;\n",
    "- **age**: edad;\n",
    "- **performance**: en escala del 1 al 5, 1 siendo el más bajo y 5 siendo la más alta;\n",
    "- **education**: niveles de educación (e.g. \"College\", \"PhD\", \"Masters\", \"Highschool\");\n",
    "- **department**: diferentes departamentos  (e.g. \"Operations\", \"Management\", etc);\n",
    "- **seniority**: en escala del 1 al 5, 1 siendo el más bajo y 5 siendo la más alta;\n",
    "- **income, bonus**: Expresados en dólares\n",
    "\n",
    "Pequeña transformación (feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base$pay <-  base$income + base$bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(base,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "Construya la matriz de correlaciones de entre las variables cuantitavias de la base de datos. Qué variables parecen razonables para usar en un modelo de regresión? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(base[,c(\"age\", \"performance\", \"seniority\", \"pay\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"corrplot\")\n",
    "library(corrplot)\n",
    "options(repr.plot.width=8, repr.plot.height=8)\n",
    "corrplot(cor(base[,c(\"age\", \"performance\", \"seniority\", \"pay\")]), method=\"circle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "Construya Figuras que permitan una comparación en la variable pay, indexada por género con las variables cualitativas de la base de datos. Qué variables parecen razonables para usar en un modelo de regresión? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gridExtra)\n",
    "library(ggplot2)\n",
    "options(repr.plot.width=16, repr.plot.height=12)\n",
    "fig2 <- ggplot(base, aes(x=factor(education), y=pay, col=gender))+geom_boxplot()\n",
    "fig3 <- ggplot(base, aes(x=factor(jobtitle), y=pay, col=gender))+geom_boxplot()+theme(axis.text.x = element_text(angle = 30, vjust = 0.5, hjust=1))\n",
    "fig4 <- ggplot(base, aes(x=factor(performance), y=pay, col=gender))+geom_boxplot()\n",
    "grid.arrange(fig2,fig3,fig4, ncol=2, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3 \n",
    "\n",
    "Conluya si tiene sentido suponer que la formación académica influye en el pago. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "levels(base$education)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ajuste2 <- lm(pay ~ factor(gender) + factor(education), data=base)\n",
    "summary(ajuste2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "\n",
    "Incluya la variable age en el modelo. Tiene sentido el modelo obtenido? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajuste3 <- lm(pay~gender + age + factor(education), data=base)\n",
    "summary(ajuste3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 6 \n",
    "Qué hace la línea de código `base[which(dffits(ajuste) > 0.5),]`? Qué puede interpretar de esto?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base[which(dffits(ajuste) > 0.5),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(influence.measures(ajuste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una observación que resalta por la diferencia que el modelo prediciría su salario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 7\n",
    "\n",
    "Monte el modelo saturado (con todas las variables). Algún cambio que llame su atención?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels(base$jobtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ajuste3 <- lm(pay~factor(jobtitle) + age + factor(performance) + factor(education) + factor(department) + factor(seniority) + gender, data=base)\n",
    "summary(ajuste3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 8\n",
    "\n",
    "Teniendo el modelo anterior, cuáles son las áreas que mejor pagan?\n",
    "\n",
    "(a) Marketing Associate\n",
    "\n",
    "(b) Software Engineer\n",
    "\n",
    "(c) Manager\n",
    "\n",
    "(d) Graphic Designer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando la diferencia en el $R^2$ de más de $80\\%$ entre el modelo más sencillo y el modelo más complejo, siendo género incluido en ambos, quiere decir que hay incidencia importante sobre la variabildiad de la información en las otras variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 9:\n",
    "\n",
    "Basado en lo anterior, considere las siguientes afirmaciones. \n",
    "\n",
    "I. Después de tener en cuenta  job title, education, performance y age, la proporción de la diferencia salarial atribuible únicamente al género es pequeña.\n",
    "\n",
    "II. Existe evidencia de que la discriminación salarial entre hombres y mujeres se debe únicamente al género.\n",
    "\n",
    "III. Hay motivos para creer que podría haber una cantidad desproporcionada de mujeres en trabajos peor pagados\n",
    "como marketing, mientras que podría haber más hombres en trabajos mejor pagados, como gerente.\n",
    "\n",
    "Elija la respuesta correcta:\n",
    "\n",
    "(a) I es correcto, II y III son incorrectos.\n",
    "\n",
    "(b) II es correcto, I y III son incorrectos.\n",
    "\n",
    "(c) I es incorrecta, II y III son correctas.\n",
    "\n",
    "(d) I y III son correctos, II es incorrecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) I y III son correctos, II es incorrecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 10:\n",
    "\n",
    "Establezca la cantidad de hombres y mujeres en los niveles de seniority y en jobtitle. Algo que llame su atención?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts <- table(base$seniority, base$gender)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts <- table(base$jobtitle, base$gender)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(base, aes(x=factor(jobtitle), y=pay, col=gender))+\n",
    "    geom_boxplot()+\n",
    "    theme(axis.text.x = element_text(angle = 30, vjust = 0.5, hjust=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 11:\n",
    "Conclusiones del caso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra conclusión inicial (basada en el modelo de regresión simple) es equivocada, no podemos concluir que exista discriminación por motivos de género. Lo anterior, ya que, como se vio recientemente, el salario también resulta una función de la posición de trabajo. Por tanto, el problema que puede ser entedido de forma exógena como discriminación, realmente se debería entender como la cantidad de mujeres que están presentes en algunas posiciones. En general, hay muchas más mujeres que hombres en posiciones muy mal pagas (Marketing Associate) y muchos más hombres que mujeres en posiciones muy bien pagas (Software Engineer y Manager). Por tanto, la recomendación hacía la forma de contratar mujeres para ciertas posiciones debería ser revisado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación de variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea central: Reducir el sesgo de los supuestos del modelo de regresión lineal que puedan presentar nuestros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.statisticshowto.com/box-cox-transformation/#:~:text=A%20Box%20Cox%20transformation%20is,a%20broader%20number%20of%20tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- runif(1000, min=10, max=50)\n",
    "y <- log(34 + 10*x + rnorm(1000, sd=30))\n",
    "plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajuste <- lm(y~x)\n",
    "summary(ajuste)\n",
    "plot(x,y)\n",
    "abline(ajuste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=7, repr.plot.height=7)\n",
    "par(mfrow=c(2,2))\n",
    "plot(ajuste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x,exp(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_exp <- exp(y)\n",
    "ajuste <- lm(y_exp~x)\n",
    "summary(ajuste)\n",
    "plot(x,y)\n",
    "abline(ajuste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,2))\n",
    "plot(ajuste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "\n",
    "#create data\n",
    "y=c(1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 6, 7, 8)\n",
    "x=c(7, 7, 8, 3, 2, 4, 4, 6, 6, 7, 5, 3, 3, 5, 8)\n",
    "\n",
    "#fit linear regression model\n",
    "model <- lm(y~x)\n",
    "summary(model)\n",
    "plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find optimal lambda for Box-Cox transformation \n",
    "bc <- boxcox(y ~ x)\n",
    "lambda <- bc$x[which.max(bc$y)]\n",
    "\n",
    "\n",
    "lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit new linear regression model using the Box-Cox transformation\n",
    "y_trans <- y^{lambda-1}/lambda\n",
    "y\n",
    "y_trans\n",
    "# new_model <- lm(((y^lambda-1)/lambda) ~ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(x,y_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ajuste2 <- lm(y_trans~x)\n",
    "summary(ajuste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initech = read.csv(\"initech.csv\")\n",
    "initech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(initech$years, initech$salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(initech$years, initech$salary)\n",
    "ajuste <- lm(salary~years, data=initech)\n",
    "summary(ajuste)\n",
    "abline(ajuste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,2))\n",
    "plot(ajuste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bc <- boxcox(initech$salary~initech$years)\n",
    "lambda <- bc$x[which.max(bc$y)]\n",
    "lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trans <- log(initech$salary)\n",
    "plot(initech$years, y_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajuste_bc <- lm(y_trans~years,data=initech)\n",
    "summary(ajuste_bc)\n",
    "plot(initech$years, y_trans)\n",
    "abline(ajuste_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,2))\n",
    "plot(ajuste_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuales <- residuals(ajuste_bc)\n",
    "mean(residuales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(lmtest) # ver https://en.wikipedia.org/wiki/Durbin%E2%80%93Watson_statistic\n",
    "dwtest(ajuste_bc) # H0: No hay autocorrelación en los errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(lmtest) #https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test\n",
    "bptest(ajuste_bc) #H0: Homoscedasticidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tseries)\n",
    "jarque.bera.test(residuales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain <- read.csv('headbrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(brain$Head.Size.cm.3., brain$Brain.Weight.grams.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajuste_brain <- lm(Brain.Weight.grams.~Head.Size.cm.3., data=brain)\n",
    "summary(ajuste_brain)\n",
    "plot(brain$Head.Size.cm.3., brain$Brain.Weight.grams.)\n",
    "abline(ajuste_brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "par(mfrow=c(2,2))\n",
    "plot(ajuste_brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuales <- residuals(ajuste_brain)\n",
    "mean(residuales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(lmtest) # ver https://en.wikipedia.org/wiki/Durbin%E2%80%93Watson_statistic\n",
    "dwtest(ajuste_brain) # H0: No hay autocorrelación en los errores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(lmtest) #https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test\n",
    "bptest(ajuste_brain) #H0: Homoscedasticidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "library(tseries)\n",
    "jarque.bera.test(residuales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trans <- log(brain$Head.Size.cm.3.)\n",
    "y_trans <- log(brain$Brain.Weight.grams.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=14, repr.plot.height=7)\n",
    "par(mfrow=c(1,2))\n",
    "plot(brain$Head.Size.cm.3., brain$Brain.Weight.grams.)\n",
    "plot(x_trans,y_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajuste2_brain <- lm(y_trans~x_trans)\n",
    "summary(ajuste2_brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuales <- residuals(ajuste2_brain)\n",
    "mean(residuales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(lmtest) # ver https://en.wikipedia.org/wiki/Durbin%E2%80%93Watson_statistic\n",
    "dwtest(ajuste2_brain) # H0: No hay autocorrelación en los errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(lmtest) #https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test\n",
    "bptest(ajuste2_brain) #H0: Homoscedasticidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tseries)\n",
    "jarque.bera.test(residuales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
