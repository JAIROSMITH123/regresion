label = T,
low = "red3",
high = "green3",
label_round = 2,
name = "Correlation Scale",
label_alpha = T,
hjust = 0.75) +
ggtitle(label = "Figura Correlación") +
theme(plot.title = element_text(hjust = 0.6))
# así, se propone el siguiente modelo.
modelo <-'
mpg ~ hp + gear + cyl + disp + carb + am + wt
hp ~ cyl + disp + carb
'
# para accesar el resumen del ajuste
summary(ajuste, fit.measures = TRUE, standardized=T,rsquare=T)
# para dibujar la figura (que ya se debió haber
# hecho a mano)
semPaths(ajuste, 'std', layout = 'circle')
# o este, para que tenga más detalles.
semPaths(ajuste,"std",
layout = 'tree',
edge.label.cex=.9,
curvePivot = TRUE)
# ejercicio
# utilizamos datos simulados y el diagrama propuesto
datos<- read.csv("ex2.csv", header=TRUE, sep=";")
str(datos)
# Al escribir el modelo de la gráfica en la
# estructura requerida, se utiliza dicha estructura
# para proceder con el modelamiento.
estructura <- '
Y2~ X4
Y3~ X4 + Y2
Y4~ Y3
'
# Se corre el modelo
modelo<- sem(estructura, data=datos)
# Se visualizan los resultados (recomendación:
# prefiera los resultados estandarizados y
# visualizar las medidas de ajuste)
summary(modelo,standardized = TRUE, fit.measures = TRUE)
modificationIndices(modelo)
lavaanPlot(model = modelo,
node_options =
list(shape = "box", fontname = "Helvetica"), edge_options = list(color = "grey"),
coefs = TRUE,
covs=TRUE,
stars = c("regress"))
# Ahora, muchos autores sugieren la importancia de
# establecer los nombres de las parámetros a ser
# estimados para poder más control sobre el análisis
estructura2<- '
Y2~ b1*X4+ b2*X5 + b3*X6
Y3~ b4*X4 + b5*Y2
Y4~ b6*Y2 + b7*Y3
'
# correr el modelo
modelo2<- sem(estructura2, data=datos)
# resumen del modelo
summary(modelo2,standardized = TRUE, fit.measures = TRUE)
estructura3<- '
#relaciones entre variables
Y2~ b1*X4+ b2*X5 + b3*X6
Y3~ b4*X4 + b5*Y2
Y4~ b6*Y2 + b7*Y3
#relaciones entre variables exógenaas (covarianzas)
X4~~X5+X6
X5~~X6
'
#El modelo
modelo3<- sem(estructura3, data=datos)
#los resultados
summary(modelo3,standardized = TRUE, fit.measures = TRUE)
#Finalmente, el Path Analysis, es importante por si sólo
# por que permite también encontrar estructuras de
# influencia entre variables. Es decir, este tipo de
# modelos son evidencia científica para afirmar
# que pueden existir influencias directas (regresión)
# e influencias indirectas.
estructura4<- '
#relaciones entre variables
Y2~ b1*X4+ b2*X5 + b3*X6
Y3~ b4*X4 + b5*Y2
Y4~ b6*Y2 + b7*Y3
#relaciones entre variables exógenas (covarianzas)
X4~~X5+X6
X5~~X6
# Efectos indirectos (útiles en este contexto)
# de X4 en Y3
Ef_X4Y3 := b1*b5
# de X4 en Y4
Ef_X4Y4 := b4*b7+b1*b5*b7+b1*b6
'
# el modelo
modelo4<- sem(estructura4, data=datos)
# la salida
summary(modelo4,standardized = TRUE, fit.measures = TRUE)
datos2<- read.csv("data2.csv",header=T,sep=",")
# la escritura del modelo
modelo<-'
#relaciones entre variables
interest~mastery+perfgoal+ses
achieve~anxiety+interest+mastery
anxiety~perfgoal+mastery
#relaciones entre variables exógenas (covarianzas)
mastery~~mastery
perfgoal~~perfgoal
ses~~ses
mastery~~perfgoal+ses
perfgoal~~ses
interest~~interest
anxiety~~anxiety
achieve~~achieve
interest~~anxiety'
# el modelo
modelo<- lavaan(modelo, data=datos2)
library(lavaan)
library(semPlot)
library(lavaanPlot)
library(GGally)
library(xtable)
# Creamos una matriz de correlación
regresion.cor <- lav_matrix_lower2full(c(1.0,0.20,1,0.24,0.30,1,0.70,0.80,0.30,1))
food <- read.csv("https://userpage.fu-berlin.de/soga/300/30100_data_sets/food-texture.csv",
row.names = "X")
str(food)
food.fa <- factanal(food, factors = 2)
food.fa
data("NIKKEI")
library(readxl)
library(qrmdata)
library(xts)
library(FinTS)
install.packages("qrmdata")
library(FinTS)
install.packages("FinTS")
library(readxl)
library(qrmdata)
library(xts)
library(FinTS)
data("NIKKEI")
NIKKEI
ts.plot(NIKKEI)
variacion<-ts(Nikkei225$var.)
library(readxl)
library(qrmdata)
library(xts)
library(FinTS)
data("NIKKEI")
ts.plot(NIKKEI)
ts.plot(NIKKEI.d)
NIKKEI.d <- diff(NIKKEI)
ts.plot(NIKKEI.d)
NIKKEI.12d <- diff(NIKKEI, 12)
ts.plot(NIKKEI.12d)
par(mfrow=c(2,2))
ts.plot(NIKKEI.12d)
ts.plot(NIKKEI.d)
par(mfrow=c(1,2))
ts.plot(NIKKEI.12d)
ts.plot(NIKKEI.d)
x <- NA
y <- x/1
y
library(DescTools)
install.packages("DescTools")
x <- as.Date("2018-10-01")
month(x)
months(x)
cbind(v1,v2)
v1 <- c(1,2,3)
v2 <- c(1,2,3)
cbind(v1,v2)
x <- 5:8
names(x) <- letters[5:8]
x
v <- 1:3
names(v) <- c("a","b","c")
v[4]<-4
V
v
names(v[4])
615000000*3/1000
(615000000*3/1000)/2
amzn.tkr = ts(getSymbols("AMZN",from = as.Date("2017-01-04"), to = as.Date("2017-10-27"),auto.assign = F))
library(quantmod)
library(tseries)
library(forecast)
library(ggplot2)
amzn.tkr = ts(getSymbols("AMZN",from = as.Date("2017-01-04"), to = as.Date("2017-10-27"),auto.assign = F))
chartSeries(amzn.tkr)
plot(diff(open))
df = data.frame(date = index(amzn.tkr), amzn.tkr, row.names=NULL)
open <- ts(df[,2])
par(mfrow=c(1,2))
plot(open)
plot(diff(open))
(ajuste2 <- arima(open, order=c(0,1,23), fixed = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,NA)))
coeftest(ajuste2)
library(lmtest)
coeftest(ajuste2)
pronostico<- forecast::forecast(ajuste2, h=12)
plot(pronostico)
pronostico<- forecast::forecast(ajuste2, h=12)
pronostico<- forecast(ajuste2, h=12)
ajuste2 <- arima(open, order=c(0,1,23), fixed = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,NA))
pronostico<- forecast::forecast(ajuste2, h=12)
library(tsoutliers)
library(forecast)
library(tseries)
library(TSA)
library(car)
library(lmtest)
set.seed(123)
par(mfrow=c(2,3))
plot(Nile)
acf(Nile)
pacf(Nile)
plot(diff(Nile))
acf(diff(Nile))
pacf(diff(Nile))
resNile1 <- tso(y = log(Nile))
resNile1$fit$call$xreg<-NULL
resNile1
resNile2 <- tso(y = Nile, types = c("AO", "LS", "TC"),
maxit = 1, discard.method = "bottom-up", tsmethod = "auto.arima",
args.tsmethod = list(allowdrift = FALSE, ic = "bic"))
resNile2
resNile2
modelo1 <- auto.arima(Nile,d=1,ic="bic")
res <- locate.outliers.oloop(Nile, modelo1, types = c("AO", "LS", "TC"))
res$outliers
## Prueba de Significancia de los Outliers (ETAPA 2)
discard.outliers(res, Nile, method = "en-masse",tsmethod.call = modelo1$call)$outliers
discard.outliers(res, Nile, method = "bottom-up",tsmethod.call = modelo1$call)$outliers
#mo <- outliers(c("AO", "LS","TC"), c(43, 29, 46))
#mo <- outliers(c("LS","TC"), c(29, 46))
mo <- outliers(c("AO"), c(43))
xreg <- outliers.effects(mo, length(Nile))
modelo2 <- arima(Nile, order = c(0, 1, 1), seasonal = list(order = c(0, 0, 0)),xreg = xreg)
modelo2
coeftest(modelo2)
JarqueBera.test(modelo2)
Box.test(residuals(modelo2), type="Ljung-Box", lag=24)
par(mfrow=c(2,2))
plot(ts(modelo2$coef[2]*xreg[,1],start=c(1871),freq=1),type="l",ylab="AO43")
#plot(ts(modelo2$coef[3]*xreg[,2],start=c(1871),freq=1),type="l",ylab="LS29")
#plot(ts(modelo2$coef[4]*xreg[,3],start=c(1871),freq=1),type="l",ylab="TC46")
fit.Nile <- Nile - residuals(modelo2)
plot(fit.Nile,ylim=c(min(Nile),max(Nile)),col="gray",type="l",lwd=3)
lines(Nile,col="red",lty=4)
abline(h=0,col="red",lty=2)
acf(residuals(modelo2)); pacf(residuals(modelo2))
pred1 <- predict(modelo2, n.ahead=6, newxreg=rep(0,6))
plot(ts(c(Nile,pred1$pred),star=c(1871),freq=1),type="l",ylab="",col="blue")
lines(pred1$pred-pred1$se, col="red", lwd=2)
lines(pred1$pred+pred1$se, col="red", lwd=2)
points(pred1$pred, type="o")
resAirP <- tso(y = log(AirPassengers), types = c("AO", "LS", "TC"),
maxit = 1, discard.method = "bottom-up", tsmethod = "arima",
args.tsmethod = list(order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1))))
resAirP
y <- arima.sim(model = list(ar = 0.7, ma = -0.4), n = 120)
plot(y,type="b", main="Simulacion ARMA")
y[15] <- -4
y[45] <- 5
y[80:120] <- y[80:120] + 5
y <- round(y, 2)
plot(y)
modelo1 <- arima(y,order=c(1,0,0))
summary(modelo1)
y <- arima.sim(model = list(ar = 0.7, ma = -0.4), n = 120)
plot(y,type="b", main="Simulacion ARMA")
y[15] <- -4
y[45] <- 5
y[80:120] <- y[80:120] + 5
y <- round(y, 2)
plot(y)
modelo1 <- arima(y,order=c(1,0,0))
summary(modelo1)
res <- locate.outliers.oloop(y, modelo1, types = c("AO", "LS", "TC"))
res$outliers
## Prueba de Significancia de los Outliers (ETAPA 2)
discard.outliers(res, y, method = "en-masse",tsmethod.call = modelo1$call)$outliers
discard.outliers(res, y, method = "bottom-up",tsmethod.call = modelo1$call)$outliers
#mo <- outliers(c("AO", "LS","TC"), c(43, 29, 46))
#mo <- outliers(c("LS","TC"), c(29, 46))
mo <- outliers(c("AO","AO","LS","AO"), c(15,45,80,6))
xreg <- outliers.effects(mo, length(y))
modelo2 <- arima(y, order = c(1, 0, 0),xreg = xreg)
modelo2
coeftest(modelo2)
JarqueBera.test(modelo2)
Box.test(residuals(modelo2), type="Ljung-Box", lag=24)
modelo2
coeftest(modelo2)
par(mfrow=c(2,3))
plot(log(airmiles),ylab='Log(airmiles)',xlab='Year', main='')
acf(log(airmiles),lag.max=40)
pacf(log(airmiles),lag.max=40)
plot(diff(diff(log(airmiles),12)),ylab='Log(airmiles)',xlab='Year', main='')
acf(diff(diff(window(log(airmiles),end=c(2001,8)),12)),lag.max=48,main='')
pacf(diff(diff(window(log(airmiles),end=c(2001,8)),12)),lag.max=48,main='')
air.m1=arimax(log(airmiles),order=c(0,1,1),seasonal=list(order=c(0,1,1),period=12),
xtransf=data.frame(I911=1*(seq(airmiles)==69),
I911=1*(seq(airmiles)==69)  ), #Fin del data.frame
transfer=list(c(0,0),c(1,0)),
xreg=data.frame(Dec96=1*(seq(airmiles)==12),
Jan97=1*(seq(airmiles)==13),
Dec02=1*(seq(airmiles)==84)),method='ML')
data(airmiles)
plot(airmiles)
identify(xy.coords(airmiles)$x,xy.coords(airmiles)$y, labels=seq(airmiles))
par(mfrow=c(2,3))
plot(log(airmiles),ylab='Log(airmiles)',xlab='Year', main='')
acf(log(airmiles),lag.max=40)
par(mfrow=c(2,3))
plot(log(airmiles),ylab='Log(airmiles)',xlab='Year', main='')
acf(log(airmiles),lag.max=40)
zpacf(log(airmiles),lag.max=40)
plot(diff(diff(log(airmiles),12)),ylab='Log(airmiles)',xlab='Year', main='')
acf(diff(diff(window(log(airmiles),end=c(2001,8)),12)),lag.max=48,main='')
pacf(diff(diff(window(log(airmiles),end=c(2001,8)),12)),lag.max=48,main='')
air.m1=arimax(log(airmiles),order=c(0,1,1),seasonal=list(order=c(0,1,1),period=12),
xtransf=data.frame(I911=1*(seq(airmiles)==69),
I911=1*(seq(airmiles)==69)  ), #Fin del data.frame
transfer=list(c(0,0),c(1,0)),
xreg=data.frame(Dec96=1*(seq(airmiles)==12),
Jan97=1*(seq(airmiles)==13),
Dec02=1*(seq(airmiles)==84)),method='ML')
air.m1
#Aquí está claro que la intervención funcionó para identificar
#los puntos atípicos.
coeftest(air.m1)
fit.air <- log(airmiles) - residuals(air.m1)
res1 <- residuals(air.m1)
par(mfrow=c(2,2))
plot(fit.air, type="b",col="red", lwd=1)
lines(log(airmiles), type="b", col="blue", lty=2)
acf(res1)
pacf(res1)
qqPlot(res1, lwd=1, pch=1)
JarqueBera.test(res1)
Box.test(res1, type="Ljung-Box", lag=24)
intv.effect <- 1*(seq(airmiles)==69)
intv.effect <- ts(intv.effect * (-0.0949) +
filter(intv.effect, filter =  0.8139, method = "rec", sides = 1) * (-0.2715))
intv.effect <- exp(intv.effect)
tsp(intv.effect) <- tsp(airmiles)
par(mfrow=c(2,1))
plot(100*(intv.effect - 1), type = "h", main = "Efecto total de la Intervención")
plot(log(airmiles))
install.packages("equatiomatic")
library(equatiomatic)
# Fit a simple model
mod1 <- lm(mpg ~ cyl + disp, mtcars)
# Give the results to extract_eq
extract_eq(mod1)
tex_preview(extract_eq(mod1))
set.seed(1234)
df <- data.frame(outcome = factor(rep(LETTERS[1:3], 100),
levels = LETTERS[1:3],
ordered = TRUE),
continuous_1 = rnorm(300, 100, 1),
continuous_2 = rnorm(300, 50, 5))
model_ologit <- MASS::polr(outcome ~ continuous_1 + continuous_2,
data = df, Hess = TRUE, method = "logistic")
model_oprobit <- MASS::polr(outcome ~ continuous_1 + continuous_2,
data = df, Hess = TRUE, method = "probit")
extract_eq(model_ologit, wrap = TRUE)
library(strucchange)
library(urca)
library(tseries)
library(lmtest)
library(vars)
data(Canada)
summary(Canada)
plot(Canada, nc = 2, xlab = "")
par(mfrow=c(3,2))
ccf(Canada[,"prod"],Canada[,"e"],type="correlation")
ccf(Canada[,"prod"],Canada[,"U"],type="correlation")
ccf(Canada[,"prod"],Canada[,"rw"],type="correlation")
ccf(Canada[,"e"],Canada[,"U"],type="correlation")
ccf(Canada[,"e"],Canada[,"rw"],type="correlation")
ccf(Canada[,"U"],Canada[,"rw"],type="correlation")
adf1 <- ur.df(Canada[, "prod"], type = "trend", lags = 2)
summary(adf1)
plot(adf1)
adf2 <- ur.df(diff(Canada[, "prod"]), type = "drift",lags = 1)
summary(adf2)
plot(adf2)
adf3 <- ur.df(Canada[, "e"], type = "trend", lags = 2)
summary(adf3)
plot(adf3)
adf4 <- ur.df(diff(Canada[, "e"]), type = "drift", lags = 1)
summary(adf4)
plot(adf4)
adf5 <- ur.df(Canada[, "U"], type = "trend", lags = 2)
summary(adf5)
plot(adf5)
adf6 <- ur.df(diff(Canada[, "U"]), type = "drift", lags = 1)
summary(adf6)
plot(adf6)
adf7 <- ur.df(Canada[, "rw"], type = "trend", lags = 4)
summary(adf7)
plot(adf7)
adf8 <- ur.df(diff(Canada[, "rw"]), type = "drift", lags = 4)
summary(adf8)
plot(adf8)
plot(diff(Canada), nc = 2, xlab = "")
VARselect(Canada, lag.max = 8, type = "both")$selection
yt <- Canada[, c("prod", "e", "U", "rw")]
str(yt)
modelo <- vars::VAR(Canada, p = 3, type = "both")
summary(modelo)
causality(modelo, cause="prod")
causality(modelo, cause="e")
causality(modelo, cause="U")
causality(modelo, cause="rw")
ser11 <- serial.test(modelo, lags.pt = 16, type = "PT.asymptotic")
ser11$serial
norm1 <- normality.test(modelo)
norm1$jb.mul
arch1 <- arch.test(modelo, lags.multi = 5)
arch1$arch.mul
plot(modelo,names="e")
plot(arch1, names = "e")
plot(stability(modelo), nc = 2)
par(mfrow=c(2,2))
plot(ts(fitted(modelo)[,"prod"],start=c(1980,4),freq=4),ylab="prod_hat",col="blue",type="l",lty=2)
lines(Canada[, "prod"],type="l")
plot(ts(fitted(modelo)[,"e"],start=c(1980,4),freq=4),ylab="e_hat",col="blue",type="l",lty=2)
lines(Canada[, "e"],type="l")
plot(ts(fitted(modelo)[,"U"],start=c(1980,4),freq=4),ylab="U_hat",col="blue",type="l",lty=2)
lines(Canada[, "U"],type="l")
plot(ts(fitted(modelo)[,"rw"],start=c(1980,4),freq=4),ylab="rw_hat",col="blue",type="l",lty=2)
lines(Canada[, "rw"],type="l")
est <- residuals(modelo)
par(mfrow=c(2,2))
acf(est[,"prod"])
acf(est[,"e"])
acf(est[,"U"])
acf(est[,"rw"])
par(mfrow=c(3,2))
ccf(est[,"prod"],est[,"e"])
ccf(est[,"prod"],est[,"U"])
ccf(est[,"prod"],est[,"rw"])
ccf(est[,"e"],est[,"U"])
ccf(est[,"e"],est[,"rw"])
ccf(est[,"U"],est[,"rw"])
vecm <- ca.jo(Canada, type = "trace", ecdet = "trend", K = 3, spec = "transitory")
summary(vecm)
vecm1 <- ca.jo(Canada, type = "eigen", ecdet = "trend", K = 3, spec = "transitory")
summary(vecm1)
vecm <- ca.jo(yt, type = "trace", ecdet = "trend", K = 3, spec = "transitory")
vecm.r1 <- cajorls(vecm, r = 1)
vecm <- ca.jo(yt, type = "trace", ecdet = "trend", K = 3, spec = "transitory")
SR <- matrix(NA, nrow = 4, ncol = 4)
SR[4, 2] <- 0
LR <- matrix(NA, nrow = 4, ncol = 4)
LR[1, 2:4] <- 0
LR[2:4, 4] <- 0
svec <- SVEC(vecm, LR = LR, SR = SR, r = 1, lrtest = FALSE, boot = TRUE, runs = 100)
summary(svec)
salida<-SVAR(modelo, estmethod = "scoring", Amat = LR, Bmat = SR,
max.iter = 100, maxls = 1000, conv.crit = 1.0e-8)
summary(salida)
LR[3, 3] <- 0
svec.oi <- update(svec, LR = LR, lrtest = TRUE, boot = FALSE)
svec.oi$LRover
svec.irf <- irf(svec, response = "U", n.ahead = 48, boot = TRUE)
plot(svec.irf)
?lm
setwd("C:/Users/Windows/Google Drive/U libertadores/2021.2/Análisis de Regresión/Clases/Regresion-Aplicada/Clase 3. Regresión Simple")
base <- read.csv('glassdoordata.csv')
head(base)
head(base,10)
base$pay <-  base$income + base$bonus
summary(base)
# install.packages("ggplot2")
library(ggplot2)
options(repr.plot.width=4, repr.plot.height=4)
ggplot(base, aes(x=gender, y=pay, col=gender))+geom_boxplot()
cars
mtcars
attach(mtcars)
names(mtcars)
ajuste1 <- lm(mpg~disp)
summary(ajuste)
summary(ajuste1)
ajuste2 <- lm(mpg~ disp+hp)
summary(ajuste2)
anova(ajuste1, ajuste2)
ajuste2 <- lm(mpg~ disp+drat)
summary(ajuste2)
anova(ajuste1, ajuste2)
ajuste2 <- lm(mpg~ disp+wt)
summary(ajuste2)
anova(ajuste1, ajuste2)
library(car)
qqPlot(x)
x <- rnorm(1000)
library(car)
qqPlot(x)
y <- rchisq(1000, df=20)
y
y <- rchisq(1000, df=20)
library(car)
qqPlot(x)
qqPlot(y)
