{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"logo.png\" width=\"500\">\n",
    "\n",
    "\n",
    "# Análisis de Regresión (2021-3)\n",
    "## Especialización en Estadística Aplicada\n",
    "#### Prof. [Sébastien Lozano Forero](https://www.linkedin.com/in/sebastienlozanoforero/) (slozanof@libertadores.edu.co)\n",
    "\n",
    "## <font color='red'>Estadística Inferencial</font>\n",
    "\n",
    "### Tabla de contenidos\n",
    "\n",
    "* [Presentación](#presentacion)\n",
    "* [Estimación Puntual](#estimacion)\n",
    "* [Distribuciones Muestrales](#distribuciones)\n",
    "* [Intervalos de Confianza](#intervalos)\n",
    "* [Pruebas de Hipótesis](#pruebas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentación <a class=\"anchor\" id=\"presentacion\"></a>\n",
    "\n",
    "<img style=\"float: right;\" src=\"sampling.png\" width=\"350\">\n",
    "\n",
    "\n",
    "**Población**: conjunto de individuos, objetos o fenómenos de los cuales se desea estudiar una o varias características.\n",
    "\n",
    "**muestra**: subconjunto de casos o individuos de una población. En diversas aplicaciones, interesa que una muestra sea representativa, y para ello debe escogerse una técnica de muestra adecuada que produzca una muestra aleatoria adecuada. (Esto se estudiará en el espacio académico de *muestreo estadístico* del programa). \n",
    "\n",
    "La estadística inferencial permite obtener conclusiones a partir de una **muestra**, pero que son aplicables a una **población**. Es necesario tener presente que la diferencia principal entre la matemática y la estadística yace en el manejo del error (en matemáticas se asume de forma determinística, mientras que en estadística se asume de forma estocástica), de esta manera, el espíritu central de la Estadística Inferencial yace en *tomar decisiones en escenarios de incerteza*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación Puntual <a class=\"anchor\" id=\"estimacion\"></a>\n",
    "\n",
    "\"Dios es el único que conoce los parámetros poblacionales, pero no nos dirá cuáles son\". \n",
    "\n",
    "Los parámetros poblacionales suponen, en una mayoría considerable de casos, el objeto de deseo máximo en estadística. Sin embargo, no es posible obtenerlos. Por tanto, una herramienta importante para **estimar** parámetros es el uso de la información disponible en la muestra. De esta manera, el problema se traduce en usar la información disponible de la mejor manera posible. En general la situación se puede entender como:\n",
    "\n",
    "<img style=\"float: right;\" src=\"blanco.jpg\" width=\"350\">\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "X_1, X_2, \\cdots, X_n \\sim f(\\theta), \\\\\n",
    "\\theta : \\text{Parámetro (escalar). } \\theta \\in \\mathbb{R}, \\text{ (puede ser vector}), \\\\\n",
    "\\hat{\\theta} : \\text{Estimador (Variable Aleatoria)}, g(X_1, \\cdots, X_n) \\text{ con } g:\\mathbb{R}^n\\to \\mathbb{R}.\\\\ \n",
    "f_{\\hat{\\theta}}(x): \\text{Función de densidad de probabilidad de } \\hat{\\theta}\n",
    "\\end{cases}\n",
    "$$\n",
    "De esta manera, se tienen varias definiciones y características\n",
    " - **Sesgo de un estimador.** $\\text{B}(\\hat{\\theta})= E(\\hat{\\theta})-\\theta$\n",
    " - **Error Cuadrático medio.** $\\text{EQM}(\\hat{\\theta}) = \\text{Var}(\\hat{\\theta})+\\text{B}^2(\\hat{\\theta})$\n",
    " - **Función de verosimilitud** $L(\\theta) = \\Pi_{i=1}^n f_{X_i}(x_i)$\n",
    " - **Función de log-verosimilitud** $\\ell (\\theta) = \\text{ln}(L(\\theta))$\n",
    " - **Estimador consistente.** $\\lim_{n \\to \\infty} \\text{Var}(\\hat{\\theta}) = 0$\n",
    " - **Estimador eficiente.** $Var(\\hat{\\theta}) = \\left\\{E\\left(\\frac{\\partial}{\\partial \\theta} \\ell (\\theta) \\right)^2\\right\\}^{-1}$ (Desigualdad de Cramer-Rao)\n",
    " - **Estimador Suficiente.** $P(X_1, \\cdots, X_n| \\theta, \\hat{\\theta}) = P(X_1, \\cdots, X_n|\\hat{\\theta})$ (Criterio de Factorización de Fisher-Neymman)\n",
    "\n",
    "Ahora, todas las definiciones anteriores, en un sentido práctico, nos dicen que la información se está utilizando de la mejor manera posible. Por tanto, podemos confiar en las estimativas númericas (tomar la fórmula del estimador y aplicarla con un conjunto determinado de datos) del estimador. \n",
    "\n",
    "Por ejemplo, la **media muestral** (sean $X_1, \\cdots, X_n$ una muestra aleatoria, $\\bar{X}=n^{-1}\\sum_{i=1}^{n} X_i$) es el mejor estimador posible para la **media poblacional** ($\\mu$) y la **varianza muestral** $S^2=\\frac{1}{n-1}\\sum_{i=1}^n (X_i- \\bar{X})^2$ es el mejor estimador posible para la **varianza poblacional** ($\\sigma^2$). Veamos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234) #semilla 1\n",
    "# generación de datos aleatorios\n",
    "x <- rnorm(200, mean=100, sd=81) # 200 datos aleatorios de una dist normal con media 100 y desviación 81.\n",
    "# # parámetro poblacional mu=100 y sigma2=81\n",
    "mean(x) # estimación de la media\n",
    "sd(x) # estimación de la desviación\n",
    "# # estimadores Xbarra=95.3214 y sigma2=82.6739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(4321) #semilla 2\n",
    "# generación de datos aleatorios\n",
    "y <- rnorm(200, mean=100, sd=81) # 200 datos aleatorios de una dist normal con media 100 y desviación 81.\n",
    "# parámetro poblacional mu=100 y sigma2=81\n",
    "mean(y) # estimación de la media\n",
    "sd(y) # estimación de la desviación\n",
    "# estimadores Xbarra=104.2923 y sigma2=75.0056"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misma ecuación, pero resultados diferentes. Así se ven las dos muestras (que vienen de la misma población y corresponden a los mismos parámetros poblacionales) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerías\n",
    "# install.packages(\"ggplot2\")\n",
    "library(ggplot2)\n",
    "library(repr)\n",
    "options(repr.plot.width=6, repr.plot.height=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frame para los datos\n",
    "data <- data.frame(tipo = c( rep(\"x\", 200), rep(\"y\", 200) ),valor = c(x,y))\n",
    "# visualización\n",
    "ggplot(data, aes(valor, fill = tipo)) + geom_density(alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuciones Muestrales <a class=\"anchor\" id=\"distribuciones\"></a>\n",
    "\n",
    "\"La distribución Normal es la distribución favorita de diosito\".\n",
    "\n",
    "<img style=\"float: right;\" src=\"normal.png\" width=\"350\">\n",
    "\n",
    "Al momento de tomar una muestra, asumimos que existirá un error asociado al hecho de no estar utilizando toda la información (población) sino una parte de ella. Adicionalmente, la intención principal es poder establecer hechos sobre estadísticos destacados. Por tanto, es de interés poder usar la información de las variables que componen la muestra en favor de conocer algún supuesto distribucional de estimadores populares. Estas distribuciones serán fundamentales para poder incoporar a nuestra batería de herramientas los intervalos de confianza y las pruebas de hipótesis. \n",
    " \n",
    "Ejemplo de la importancia de tales distribuciones, es el **Teorema del Límite Central (TLC)** que establece: \n",
    "$$\n",
    "X_1, X_2, \\cdots, X_n \\sim f(\\mu, \\sigma^2), \\text{ (f es cualquier distribución), entonces } \\bar{X}\\sim N(\\mu, \\sigma^2/n)\n",
    "$$\n",
    " \n",
    "Nuestro interés será utilizar diferentes distribuciones muestrales para poder establecer relaciones entre probabilidades y cuantiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $X_1,\\cdots, X_n \\sim N(\\mu, \\sigma^2)$, las siguientes son resultados o distribuciones muestrales asociadas a la distribución normal.\n",
    " - **Normal.** $Z=\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}}\\sim N(0,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $Z\\sim N(0,1)$. Así, $P(Z>z_{\\alpha})=\\alpha$, donde $z_{\\alpha}$ es cuantil y $\\alpha$ es probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal <- rnorm(1000000) #1000 datos de una distribución normal estándar\n",
    "hist(normal, prob=TRUE, col=\"grey\", main =\"Histograma de la dist normal\", ylab=\"Densidad\") \n",
    "lines(density(normal), col=\"blue\", lwd=2) \n",
    "lines(density(normal, adjust=2), lty=\"dotted\", col=\"darkgreen\", lwd=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **t-student.** $T=\\frac{\\bar{X}-\\mu}{S/\\sqrt{n}}\\sim t_{(n-1)}$\n",
    " \n",
    " Sea $T\\sim t_{(n-1)}$. Así, $P(T>t_{(n),\\alpha})=\\alpha$, donde $T_{(n),\\alpha}$ es cuantil y $\\alpha$ es probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T <- rt(10000, df=25) #1000 datos de una distribución t\n",
    "hist(T, prob=TRUE, col=\"grey\", main =\"Histograma de la dist t-student\", ylab=\"Densidad\") \n",
    "lines(density(T), col=\"blue\", lwd=2)\n",
    "lines(density(T, adjust=2), lty=\"dotted\", col=\"darkgreen\", lwd=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **chi-cuadrado** $\\chi=\\frac{(n-1)S^2}{\\sigma^2}\\sim \\chi^2_{(n-1)}$\n",
    "\n",
    " Sea $\\chi \\sim \\chi^2_{(n-1)}$. Así, $P(\\chi >\\chi^2_{(n),\\alpha})=\\alpha$, donde $\\chi^2_{(n),\\alpha}$ es cuantil y $\\alpha$ es probabilidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi <- rchisq(100000, df=25) #10000 datos de una distribución chi\n",
    "hist(chi, prob=TRUE, col=\"grey\", main =\"Histograma de la dist Chi cuadrado\", ylab=\"Densidad\") # prob=TRUE for probabilities not counts\n",
    "lines(density(chi), col=\"blue\", lwd=2) # add a density estimate with defaults\n",
    "lines(density(chi, adjust=2), lty=\"dotted\", col=\"darkgreen\", lwd=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sean $X_1,\\cdots, X_n \\sim N(\\mu_X, \\sigma_X^2)$ y $Y_1,\\cdots, Y_m \\sim N(\\mu_Y, \\sigma_Y^2)$ la siguiente es una distribución muestral asociadas a la distribución normal.\n",
    "\n",
    "- **F** $F =\\left(\\frac{S_X}{S_Y}\\right)^2\\left(\\frac{\\sigma_Y}{\\sigma_X}\\right)\\sim F_{(n-1,m-1)}$ \n",
    "\n",
    " Sea $F \\sim F_{(n-1,m-1)}$. Así, $P(F >F_{(n-1,m-1),\\alpha})=\\alpha$, donde $\\chi^2F_{(n-1,m-1),\\alpha}$ es cuantil y $\\alpha$ es probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F <- rf(1000000, df1=25, df2=20) #10000 datos de una distribución F\n",
    "hist(F, prob=TRUE, col=\"grey\", main =\"Histograma de la dist F\", ylab=\"Densidad\") # prob=TRUE for probabilities not counts\n",
    "lines(density(F), col=\"blue\", lwd=2) # add a density estimate with defaults\n",
    "lines(density(F, adjust=2), lty=\"dotted\", col=\"darkgreen\", lwd=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervalos de Confianza <a class=\"anchor\" id=\"intervalos\"></a>\n",
    "\n",
    "<img style=\"float: right;\" src=\"IC.png\" width=\"350\">\n",
    "\n",
    "Los intervalos de confianza son la \"evolución\" natural de la estimación puntual al tratarse de una metodología que no intenta gastar \"su única bala\" estimando un único parámetro, sino que intenta barrer sobre un intervalo numérico para, con una probabilidad razonablemente alta ($1-\\alpha$, donde $\\alpha$ es llamada de *significancia*), el intervalo puede contener al parámetro. Esto es, \n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "X_1, X_2, \\cdots, X_n \\sim f(\\theta), \\\\\n",
    "\\theta : \\text{Parámetro (escalar). } \\theta \\in \\mathbb{R}, \\\\\n",
    "\\hat{\\theta}_U, \\hat{\\theta}_L: \\text{Estimadores (en este contexto, límites inferior y superior, respectivamente)}.\\\\ \n",
    "\\alpha \\in (0,1): \\text{Significancia}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Decimos que $\\left(\\hat{\\theta}_U, \\hat{\\theta}_L\\right)$ es un Intervalo de Confianza (IC) para $\\theta$, con confianza del $100(1-\\alpha)\\%$, si $P\\left(\\theta \\text{ esté contenido en } (\\hat{\\theta}_U; \\hat{\\theta}_L)\\right) = 1-\\alpha.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, las distribuciones muestrales son herramientas con las que se dota de aleatoriedad a los Intervalos de confianza. Así, regularmente en Estadística Inferencial se estudia la construcción de Intervalos de confianza clásicos, a partir de las distribuciones muestrales. Algunos intervalos particulares: \n",
    "- Un IC para $\\mu$ con $\\sigma^2$ conocido. ($X_1, X_2, \\cdots, X_n \\sim N(\\mu, \\sigma^2)$), con el $100(1-\\alpha)\\%$ de confianza, está dado por $\\left(X \\pm \\frac{Z_{\\alpha/2}\\sigma}{\\sqrt{n}}\\right)$. Es decir, $P\\left(\\left(X \\pm \\frac{Z_{\\alpha/2}\\sigma}{\\sqrt{n}}\\right) \\text{ contenga a } \\mu\\right) = 1-\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validación por ciclos Monte Carlo. (ver https://en.wikipedia.org/wiki/Monte_Carlo_method)\n",
    "cont <- 0 #contador \n",
    "mu <- 100 #parámetro en la simulación\n",
    "alpha <- 0.05 #nivel de significancia\n",
    "sigma <- 10 #desviación estándar\n",
    "n <- 100 #tamaño de muestra\n",
    "for(i in 1:10000){#10000 réplicas\n",
    "muestra <- rnorm(n, mean=mu, sd=sigma) #mu=100 (desconocido) y sd= 10 (conocido)\n",
    "Xbarra <- mean(muestra)\n",
    "s <- sd(muestra)\n",
    "LI <- Xbarra-qt(alpha/2, df= n-1, lower.tail=F)*s/sqrt(n)\n",
    "LS <- Xbarra+qt(alpha/2, df= n-1, lower.tail=F)*s/sqrt(n)\n",
    "if(LI <= mu & mu <= LS){\n",
    "    cont <- cont+1\n",
    "}\n",
    "}\n",
    "print(paste(\"El intervalo contuvo al parámetro el\", cont/100, \"% de las réplicas \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Un IC para $\\mu$ con $\\sigma^2$ desconocido. ($X_1, X_2, \\cdots, X_n \\sim N(\\mu, \\sigma^2)$), con el $100(1-\\alpha)\\%$ de confianza, está dado por $\\left(X \\pm \\frac{t_{(n-1),\\alpha/2}S}{\\sqrt{n}}\\right)$\n",
    "- Un IC para $\\sigma^2$ con $\\mu$ conocido. ($X_1, X_2, \\cdots, X_n \\sim N(\\mu, \\sigma^2)$), con el $100(1-\\alpha)\\%$ de confianza, está dado por $\\left(\\frac{(n-1)S^2}{\\chi^2_{(n),\\alpha/2}};\\frac{(n-1)S^2}{\\chi^2_{(n),1-\\alpha/2}} \\right)$\n",
    "- Un IC para $\\sigma^2$ con $\\mu$ desconocido. ($X_1, X_2, \\cdots, X_n \\sim N(\\mu, \\sigma^2)$), con el $100(1-\\alpha)\\%$ de confianza, está dado por $\\left(\\frac{(n-1)S^2}{\\chi^2_{(n-1),\\alpha/2}};\\frac{(n-1)S^2}{\\chi^2_{(n-1),1-\\alpha/2}} \\right)$\n",
    "- Un IC para $p$. (El estimador es $\\hat{p}= X/n$, donde $X\\sim Bn(n,p$)), con el $100(1-\\alpha)\\%$ de confianza, está dado por \n",
    "$\\left(\\hat{p}\\pm Z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas de Hipótesis <a class=\"anchor\" id=\"pruebas\"></a>\n",
    "\n",
    "<img style=\"float: right;\" src=\"juez.jpeg\" width=\"350\">\n",
    "\n",
    "\"Todos somos inocentes hasta que se demuestre lo contrario\".\n",
    "\n",
    "#### Método Científico\n",
    "    \n",
    "i) **Plantear teorías**. La hipótesis es la explicación que se da a partir de las observaciones realizadas. De este modo, se presenta como una posible teoría. Sin embargo, habrá que tener en cuenta que una hipótesis siempre será una posibilidad, pero que será necesario reforzar mediante nuevos estudios, para lo que será necesario llevar a cabo una serie de experimentos.\n",
    "    \n",
    "ii) **Recopilar evidencias**. Este paso es posterior a la hipótesis y su función principal será darle validez mediante experimentos que sirvan para demostrar la veracidad de la hipótesis planteada. En el caso de que los experimentos lleven a negar la hipótesis, será necesario descartarla y formular una nueva hipótesis que responda de forma satisfactoria a las observaciones llevadas a cabo durante la experimentación y la observación.\n",
    "    \n",
    "iii) **Tomar una decisión**. Una vez que la experimentación haya servido para demostrar que la hipótesis planteada tiene sentido, se elaborará una teoría. La teoría será el resultado de aquellas hipótesis que tengan una probabilidad mayor de ser confirmadas como ciertas.\n",
    "\n",
    "#### Elementos de una Prueba de Hipótesis \n",
    "\n",
    "1. Hipótesis (suponen una partición de la realidad)\n",
    "$$\n",
    "\\begin{cases}\n",
    "H_0: \\text{Hipótesis Nula}\\\\\n",
    "H_1: \\text{Hipótesis Alternativa}\n",
    "\\end{cases}\n",
    "$$\n",
    "2. Dada una muestra, se obtiene el estadístico $\\tau\\stackrel{H_0}{\\sim} \\text{Distribución nula}$ y $\\tau\\stackrel{H_1}{\\sim} \\text{Distribución Alternativa}$. Como asumimos $H_0$ como verdadera, nos quedaremos también con la distribución nula hasta que se demuestre lo contrario.\n",
    "3. Regla de decisión: $p$-valor (probabilidad) o valor crítico (cuantil)\n",
    "\n",
    "Ahora, en últimas, las pruebas de hipótesis son usadas para tomar decisiones. \n",
    "\n",
    "<img style=\"float: center;\" src=\"errores.jpeg\" width=\"500\">\n",
    "\n",
    "De esta manera, sean:\n",
    "- $\\alpha =P(\\text{Error Tipo 1})= P(\\text{Rechazar } H_0|H_0 \\text{ es Verdadera})$\n",
    "- $\\beta =P(\\text{Error Tipo 2})= P(\\text{No rechazar } H_0|H_0 \\text{ es falsa})$\n",
    "\n",
    "$\\alpha$ es llamada de **significancia estadística** y $1-\\beta$ es llamado de **Poder de la prueba**. \n",
    "\n",
    "En general, para aplicar pruebas de hipótesis, basta tener presente los tres pasos fundamentales. Todas las pruebas de hipótesis se pueden entender de esa manera. Algunas pruebas para una población: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Una prueba para $\\mu$ con $\\sigma^2$ desconocido. ($X_1, X_2, \\cdots, X_n \\sim N(\\mu, \\sigma^2)$), con $100\\alpha\\%$ de significancia, está dado por \n",
    "\n",
    "i. Planteamiento de Hipótesis\n",
    "\n",
    "$$\\begin{cases}\n",
    "H_0: \\mu = \\mu_0 (\\mu_0\\text{ es conocido})\\\\\n",
    "H_1: \n",
    "\\begin{cases}\n",
    "\\mu > \\mu_0 (\\text{ Prueba a cola derecha [Caso 1]})\\\\\n",
    "\\mu < \\mu_0 (\\text{ Prueba a cola izquierda [Caso 2]})\\\\\n",
    "\\mu \\neq \\mu_0 (\\text{ Prueba bicaudal [Caso 3]})\\\\\n",
    "\\end{cases}\n",
    "\\end{cases}\n",
    "$$\n",
    "ii. Estadístico de prueba. $Z_{Est}=\\frac{\\bar{X}-\\mu_0}{\\sigma/\\sqrt{n}}\\stackrel{H_0}{\\sim} N(0,1)$\n",
    "\n",
    "iii. Regla de Rechazo. Hay evidencia significativa para el rechazo de $H_0$ en favor de $H_1$ con $100\\alpha\\%$ si $p-$valor $< \\alpha$. Suponga que $Z\\sim N(0,1)$, entonces $p-$ valor $=P(Z>|Z_{Est}|)$ para los casos 1 y 2; $p-$ valor $=2P(Z>|Z_{Est}|)$ para el caso 3. \n",
    "<img style=\"float: center;\" src=\"mu.jpeg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos la prueba de Hipótesis $H_0: \\mu = 25$ vs $H_1: \\mu \\neq 25$ con $\\bar{X}=22$, $\\sigma=2$, $n=40$ y $\\alpha = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validación por ciclos Monte Carlo.\n",
    "cont <- 0 #contador \n",
    "mu0 <- 25 #parámetro en la simulación (H0 es verdadera)\n",
    "alpha <- 0.1 #nivel de significancia\n",
    "sigma <- 2 #desviación estándar\n",
    "n <- 40 #tamaño de muestra\n",
    "for(i in 1:10000){#10000 réplicas\n",
    "muestra <- rnorm(n, mean=mu0, sd=sigma) #mu=100 (desconocido) y sd= 10 (conocido)\n",
    "Xbarra <- mean(muestra)\n",
    "Zest <- (Xbarra - mu0)/(sigma/sqrt(n))\n",
    "p.val <- 2*pnorm(abs(Zest), lower.tail=F)\n",
    "if(p.val<alpha){\n",
    "    cont <- cont+1\n",
    "}\n",
    "}\n",
    "print(paste(\"El ciclo rechazó el\", cont/100, \"% de las pruebas \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas de hipótesis no paramétricas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "H_0: \\text{Los datos son normalmente distribuidos}\\\\\n",
    "H_1: \\text{Los datos no son normalmente distribuidos (no $H_0$)}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tseries)\n",
    "jarque.bera.test(rchisq(1000, df=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
