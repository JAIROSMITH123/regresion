{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"logo.png\" width=\"500\">\n",
    "\n",
    "\n",
    "# Análisis de Regresión (2021-3)\n",
    "## Especialización en Estadística Aplicada\n",
    "#### Prof. [Sébastien Lozano Forero](https://www.linkedin.com/in/sebastienlozanoforero/) (slozanof@libertadores.edu.co)\n",
    "\n",
    "## <font color='red'>Introducción a la Regresión Logística</font>\n",
    "\n",
    "### Tabla de contenidos\n",
    "\n",
    "* [Modelo de Regresión Logística](#modelo)\n",
    "* [Resultados Generales](#resultados)\n",
    "* [Supuestos](#supuestos)\n",
    "* [Validación de Supuestos](#validacion) \n",
    "* [Ejemplo](#ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regresión Logística <a class=\"anchor\" id=\"modelo\"></a>\n",
    "\n",
    "Suponga alguna de las siguientes situaciones \n",
    "- Un sujeto operado se infecta o no durante cierto lapso post-operatorio.\n",
    "- Un bebé nace con o sin malformación congénita.\n",
    "- Un paciente hospitalizado muere o no antes del alta.\n",
    "- A los tres meses de vida, un niño ha dejado de lactar o aún se mantiene alimentándose con leche materna.\n",
    "- Un año después de una intervención quirúrgica, se ha resuelto o no el problema que la origino´.\n",
    "- Después de un tratamiento de quimioterapia en un paciente con cáncer de pulmón se observa alguno de los siguientes resultados sobre la enfermedad:  aumento, no cambio, remisión parcial, remisión completa.\n",
    "\n",
    "\n",
    "\n",
    "El modelo de regresión lineal tradicional utiliza la linealidad para describir la relación entre el valor esperado de la variable respuesta y un conjunto de variables explicativas asumiendo que la distribución de la variable respuesta es normal.\n",
    "Los modelos lineales generalizados (MLG) extiende el modelo de regresión lineal tradicional con el fin de poder caracterizar variables respuestas con distribuciones no normales y funciones no lineales de la media. Los MLG tienen tres componentes:\n",
    "\n",
    "    1. Componente aleatorio: \n",
    "Este componente especifica la variable de respuesta $y$ y su distribución de probabilidad. \n",
    "\n",
    "Nota 1: La distribución de la variable respuesta debe ser un miembro de la familia exponencial de distribuciones. \n",
    "Se dice que una distribución con densidad de probabilidad o función de masa para una variable aleatoria $y$ pertenece a la familia exponencial de distribuciones sí, y solo sí, puede expresarse de la forma general dada por: \n",
    "$$\n",
    "f(y;\\theta,\\phi)=\\text{exp}\\left[\\frac{y\\theta−b(\\theta)}{a(\\phi)} +c(y,\\phi)\\right]\n",
    "$$\n",
    "donde\n",
    "\n",
    "- $\\theta$ es llamado el parámetro natural o canónico y representa la localización.\n",
    "\n",
    "- $\\phi$ es llamado el parámetro de dispersión y representa la escala. \n",
    "\n",
    "- $b(\\theta)$ se define como la función cumulante y es importante porque relaciona el parámetro canónico con la media y varianza de $y$. \n",
    "\n",
    "Nota 2: Las observaciones sobre esa distribución $y=(y_1,y_2,\\cdots,y_n)^\\top$   se consideran independientes. \n",
    "\n",
    "A continuación, los principales elementos para tres de las distribuciones que pueden modelarse con GLMs\n",
    "\n",
    "|                 | Regresión Lineal | Regresión Poisson | Regresión Logística |\n",
    "|------------------------|------------------------|-------------------------|---------------------------|\n",
    "| $Y \\mid {\\bf X} = {\\bf x}$ | $N(\\mu({\\bf x}), \\sigma^2)$    | $\\text{Pois}(\\lambda({\\bf x}))$          | $\\text{Bern}(p({\\bf x}))$                                              |\n",
    "| **Nombre de la Distribución**                           | Normal                         | Poisson                                  | Bernoulli (Binomial)                                                   |\n",
    "| $\\text{E}[Y \\mid {\\bf X} = {\\bf x}]$            | $\\mu({\\bf x})$                 | $\\lambda({\\bf x})$                       | $p({\\bf x})$                                                           |\n",
    "| **Soporte**                                     | Real: $(-\\infty, \\infty)$      | Entero: $0, 1, 2, \\ldots$               | Entero: $0, 1$                                                        |\n",
    "| **Uso**                                       | Data Numérica                 | Data de Conteo (Entero)                     |Data binaria                                      |\n",
    "| **Nombre la ligación**                                   | Identity                       | Log                                      | Logit                                                                  |\n",
    "| **Link Function** | $\\eta({\\bf x}) = \\mu({\\bf x})$ | $\\eta({\\bf x}) = \\log(\\lambda({\\bf x}))$ | $\\eta({\\bf x}) = \\log \\left(\\frac{p({\\bf x})}{1 - p({\\bf x})} \\right)$          |\n",
    "| **Mean Function**                               | $\\mu({\\bf x}) = \\eta({\\bf x})$ | $\\lambda({\\bf x}) = e^{\\eta({\\bf x})}$   | $p({\\bf x})= \\frac{1}{1 + e^{-\\eta({\\bf x})}}$ |\n",
    "\n",
    "    2. Componente sistemático o predictor lineal:\n",
    "\n",
    "El componente sistemático o predictor lineal es una combinación lineal del conjunto de p covariables identificadas por el analista que asocia el efecto estas variables auxiliares sobre la media de la variable respuesta.\n",
    "\n",
    "Para un vector de parámetros $\\beta=(\\beta_1,\\beta_2,\\cdots, \\beta_p )^\\top$ desconocidos (a ser estimados posteriormente) y una matriz de información $X$ que contiene todos los $n$  (Nota: $p<n$) valores observados de un conjunto de $p$ variables explicativas, el predictor lineal tiene la forma $X\\beta$.\n",
    "\n",
    "<img style=\"float: right;\" src=\"logi.png\" width=\"500\">\n",
    "\n",
    "La recta de regresión de un modelo de regresión lineal  se extiende de forma ilimitada entre $(-\\infty, \\infty)$.\n",
    "Si bien los valores de la recta de regresión se interpretan en el rango de valores de $x$ observados en la muestra y tienen un sentido interpretativo, descartando valores de predicción imposibles a partir de los datos estudiados. No obstante, también puede suceder que a pesar de considerar el rango de valores de la muestra los valores pronosticados sean\n",
    "valores imposibles. Es el caso que se puede dar cuando consideramos en la regresión lineal variables dicotómicas de la variable dependiente, codificadas con 0 y 1, donde los valores predichos pueden ser inferiores a 0 y superiores a 1, fuera del rango definido por la variable dependiente. La regresión logística resuelve este tipo de problema usando una función no lineal como es la función logística. Con esta función se pueden efectuar predicciones comprendidas entre un mínimo y un máximo. El modelo de regresión logística es un modelo no lineal que utiliza el método de máxima verosimilitud, un procedimiento iterativo que en fases sucesivas ajusta el modelo.\n",
    "\n",
    "En últimas, este problema del \"idioma\" que hablan los componentes sistemático y aleatorio se resuelve con     \n",
    "\n",
    "    3. Una función de enlace\n",
    "\n",
    "En una función g que aplicada a cada componente de $E(y)$ lo relaciona con el predictor lineal, es decir, $g(E(y))= X\\beta$. Usualmente se denota con el símbolo $\\eta$.\n",
    "\n",
    "En otras palabras, la función de enlace es una transformación de la media de la variable respuesta de modo que los efectos de las covariables sean aditivos y las restricciones sobre los datos se mantengan\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera, se la función sigmoide (sigmoid function) es útil para poder \"traducir\" la información de un componente a otro. Es decir, es una excelente opción (ojo, no es la única) a ser una función de ligación  $$f(x)= \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "Así, el **modelo de regresión logística** se gesta del interés de poder predecir el comportamiento de las variables $y_1, \\cdots, y_n\\sim Br(p)$, con \n",
    "\n",
    "\\begin{cases}\n",
    "p = P(y_t=1), t =1, 2\\cdots, n.\\\\\n",
    "1-p = P(y_t=0), t =1, 2\\cdots, n.,\n",
    "\\end{cases}\n",
    "\n",
    "a partir del conocimiento consignado en las variables exógenas. De esta manera, el modelo está dado por \n",
    "$$\n",
    "p= P(y_t|x_1, \\cdots, x_p)=\\frac{1}{1+\\exp(-\\beta_0 -\\beta_1x_1-\\beta_2x_2-\\cdots-\\beta_px_p)}\n",
    "$$\n",
    "o de forma equivalente, como \n",
    "$$\n",
    "\\log\\left(\\frac{p}{1-p}\\right)= \\log\\left(\\frac{P(y_t|x_1, \\cdots, x_p)}{1-P(y_t|x_1, \\cdots, x_p)}\\right)=\\beta_0 +\\beta_1x_1+\\beta_2x_2+\\cdots+\\beta_px_p\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Donde: \n",
    "- $\\beta_0, \\beta_1, \\cdots, \\beta_p$ son parámetros poblacionales a ser estimados.\n",
    "- $y$ representa la *variable respuesta*\n",
    "- $x_1,\\cdots x_p$ representan las *variables predictoras*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ISLR)\n",
    "datos <- Default\n",
    "\n",
    "# Se recodifican los niveles No, Yes a 1 y 0\n",
    "datos <- datos %>%\n",
    "         select(default, balance) %>%\n",
    "         mutate(default = recode(default,\n",
    "                                 \"No\"  = 0,\n",
    "                                 \"Yes\" = 1))\n",
    "head(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste de un modelo lineal por mínimos cuadrados.\n",
    "modelo_lineal <- lm(default ~ balance, data = datos)\n",
    "\n",
    "# Representación gráfica del modelo.\n",
    "ggplot(data = datos, aes(x = balance, y = default)) +\n",
    "  geom_point(aes(color = as.factor(default)), shape = 1) + \n",
    "  geom_smooth(method = \"lm\", color = \"gray20\", se = FALSE) +\n",
    "  theme_bw()  +\n",
    "  labs(title = \"Regresión lineal por mínimos cuadrados\",\n",
    "       y = \"Probabilidad default\") +\n",
    "  theme(legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y peor aún, para predecir:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict(object = modelo_lineal, newdata = data.frame(balance = 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Generales <a class=\"anchor\" id=\"resultados\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso de estimación de parámetros\n",
    "\n",
    "Podemos escribir el modelo de regresión muestral correspondiente al modelo como\n",
    "$$\n",
    "\\log\\left(\\frac{p}{1-p}\\right)= \\log\\left(\\frac{P(y_t|x_1, \\cdots, x_p)}{1-P(y_t|x_1, \\cdots, x_p)}\\right)=\\beta_0 +\\beta_1x_1+\\beta_2x_2+\\cdots+\\beta_px_p\n",
    "$$\n",
    "\n",
    "\t\n",
    "En notación matricial, este modelo de regresión muestral se representa como\n",
    "$$\n",
    "\\log\\left(\\frac{p}{1-p}\\right)= \\log\\left(\\frac{P(Y|X)}{1-P(Y|X)}\\right)=X\\beta\n",
    "$$\n",
    "donde\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\mathbf{Y}=\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{pmatrix}, & \\mathbf{X}=\\begin{pmatrix}\n",
    "1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\\n",
    "1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n",
    "\\vdots & \\vdots & \\vdots & & \\vdots \\\\\n",
    "1 & x_{n1} & x_{n2} & \\cdots & x_{np} \\\\\n",
    "\\end{pmatrix}, \n",
    "\\mathbf{\\beta}=\\begin{pmatrix}\n",
    "\\beta_0 \\\\\n",
    "\\beta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\beta_p\n",
    "\\end{pmatrix}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Deseamos encontrar el vector de estimadores de mínimos cuadrados, $\\mathbf{\\beta}$, que minimiza la función de log-verosimilitud\n",
    "\n",
    "$$L(\\beta) = \\sum_{i=1}^{p} y_i \\text{ln}(p_i)+(1-y_i)\\text{ln}(1-p_i)$$\n",
    "\n",
    "El resultado de tal proceso de estimación no tiene forma cerrada (es decir, se puede despegar \"a manos\"), por tanto, son necesarios algunos métodos númericos para hallar tales estimativas (típicamente son esquemas iterativos al estilo Newton-Rhapson). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pruebas de hipótesis\n",
    "\n",
    "En general, va a ser de nuestro interés obtener evidencia empírica de la validez estadística de los parámetros que indexan el modelo. Para esto, se hace necesario introducir pruebas de hipótesis para los parámetros. \n",
    "\n",
    "Considere, la prueba de las hipótesis para $\\beta_i$:\n",
    "\\begin{align*}\n",
    "H_0: \\, \\beta_i &=\\beta_{i0} (\\beta_{i0} \\text{conocido})\\\\\n",
    "H_1: \\, \\beta_i &\\neq \\beta_{i0}\n",
    "\\end{align*}\n",
    "\n",
    "que tiene como estadístico de prueba:\n",
    "\t\n",
    "$$\n",
    "Z_{Est}=\\frac{\\hat{\\beta}_1-\\beta_{10}}{s\\{\\hat{\\beta}_1\\}} \\sim N(0,1)\n",
    "$$\n",
    "\t\n",
    "y la regla de decisión para el nivel de significancia $\\alpha$ es $p$-valor $<\\alpha$ donde $p$-valor $= 2P(Z>|Z_{Est}|)$ con $Z\\sim N(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de razón de verosimilitud\n",
    "\n",
    "Considere el siguiente modelo saturado,\n",
    "\n",
    "$$\n",
    "\\log\\left(\\frac{p({\\bf x_i})}{1 - p({\\bf x_i})}\\right) = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_{(p-1)} x_{i(p-1)} + \\epsilon_i\n",
    "$$\n",
    "\n",
    "El modelo tiene $p - 1$ predictores, para un  total of $p$ parámetros. Notamos como  $\\hat{\\beta}_{\\text{Full}}$ al vector de estimaciones de máxima verosimilitud\n",
    "\n",
    "Ahora, considere el siguiente modelo nulo\n",
    "\n",
    "$$\n",
    "\\log\\left(\\frac{p({\\bf x_i})}{1 - p({\\bf x_i})}\\right) = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_{(q-1)} x_{i(q-1)} + \\epsilon_i\n",
    "$$\n",
    "\n",
    "donde $q < p$. Este modelo $q - 1$ predictors,  en total $q$ parámetros. Nuevamente, sea $\\hat{\\beta}_{\\text{Full}}$ el vector de estimaciones de máxima verosimilitud\n",
    "\n",
    "La diferencia entre estos dos modelos se puede estudiar a través de una prueba de hipótesis\n",
    "\n",
    "$$\n",
    "H_0: \\beta_q = \\beta_{q+1} = \\cdots = \\beta_{p - 1} = 0.\n",
    "$$\n",
    "\n",
    "Lo que implica que el modelo reducido está anidado en el modelo saturado. Así se define la estadística, $D$,\n",
    "\n",
    "$$\n",
    "D = -2 \\log \\left( \\frac{L(\\boldsymbol{\\hat{\\beta}_{\\text{Null}}})} {L(\\boldsymbol{\\hat{\\beta}_{\\text{Full}}})} \\right) = 2 \\log \\left( \\frac{L(\\boldsymbol{\\hat{\\beta}_{\\text{Full}}})} {L(\\boldsymbol{\\hat{\\beta}_{\\text{Null}}})} \\right) = 2 \\left( \\ell(\\hat{\\beta}_{\\text{Full}}) - \\ell(\\hat{\\beta}_{\\text{Null}})\\right)\n",
    "$$\n",
    "\n",
    "donde $L$ denota la función de verosimilitud y $\\ell$ denota la función de log-verosimilitud. Para tamaños de muestra grande (más de 50), este estadístico de test tiene distribución chi cuadrado. \n",
    "\n",
    "$$\n",
    "D \\overset{\\text{approx}}{\\sim} \\chi^2_{k}\n",
    "$$\n",
    "\n",
    "con $k = p - q$, la diferencia en el número de parámetros en los dos modelos.\n",
    "\n",
    "Este test, frecuentemente referido como **test de razón de verosimilitud**, es análogo a ANOVA ($F$) para regresión logística. Curiosamente, para implementar este test se usa la función `anova()` de `R`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Razón de chances (odds ratio)\n",
    "  \n",
    "En la regresión lineal simple, se modela el valor de la variable dependiente $y$ en función del valor de las variables independientes $X$. Sin embargo, en la regresión logística, se modela la probabilidad de que la variable respuesta $y$ pertenezca al nivel de referencia 1 en función del valor que adquieran los predictores, mediante el uso de LOG of ODDs.\n",
    "\n",
    "Supónga que la probabilidad de que un evento sea verdadero es de 0.8, por lo que la probabilidad de evento falso es de 1 - 0.8 = 0.2. Los ODDs o razón de probabilidad  se definen como el ratio entre la probabilidad de evento verdadero y la probabilidad de evento falso pq. En este caso los ODDs de verdadero son 0.8 / 0.2 = 4, lo que equivale a decir que se esperan 4 eventos verdaderos por cada evento falso.\n",
    "\n",
    "La trasformación de probabilidades a ODDs es monótona, si la probabilidad aumenta también lo hacen los ODDs, y viceversa. El rango de valores que pueden tomar los ODDs es de $[0,\\infty]$. Dado que el valor de una probabilidad está acotado entre $[0,1]$ se recurre a una trasformación log (existen otras) que consiste en el logaritmo natural de los ODDs. Esto permite convertir el rango de probabilidad previamente limitado a $[0,1]$ a $[−\\infty,+\\infty]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|p\t|odds\t|Log(odds)|\n",
    "|----|---|---|\n",
    "0.001|0.001001|\t-6.906755|\n",
    "0.01|\t0.010101|\t-4.59512|\n",
    "0.2|\t0.25|\t-1.386294|\n",
    "0.3|\t0.4285714|\t-0.8472978|\n",
    "0.4|\t0.6666667|\t-0.4054651|\n",
    "0.5|\t1|\t0|\n",
    "0.6|\t1.5|\t0.4054651|\n",
    "0.7|\t2.333333|\t0.8472978|\n",
    "0.8|\t4|\t1.386294|\n",
    "0.9|\t9|\t2.197225|\n",
    "0.999|\t999|\t6.906755|\n",
    "0.9999|\t9999|\t9.21024|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ODDs y el logaritmo de ODDs cumplen que:\n",
    "- Si p(verdadero) = p(falso), entonces odds(verdadero) = 1\n",
    "- Si p(verdadero) < p(falso), entonces odds(verdadero) < 1\n",
    "- Si p(verdadero) > p(falso), entonces odds(verdadero) > 1\n",
    "- A diferencia de la probabilidad que no puede exceder el 1, los ODDs no tienen límite superior.\n",
    "- Si odds(verdadero) = 1, entonces logit(p) = 0\n",
    "- Si odds(verdadero) < 1, entonces logit(p) < 0\n",
    "- Si odds(verdadero) > 1, entonces logit(p) > 0\n",
    "- La transformación logit no existe para p = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición de la muestra (in/out)\n",
    "\n",
    "<img style=\"float: center;\" src=\"test.png\" width=\"500\">\n",
    "\n",
    "Los datos de entrenamiento o “training data” son los datos que se usan para *entrenar* (en una perspectiva más amplia, *aprender*) un modelo. La calidad del modelo de regresión logística va a ser directamente proporcional a la calidad de los datos. Por ello las labores de limpieza, depuración o “data wrangling” deberán ser importantes\n",
    "\n",
    "Los datos de prueba, validación o “testing data“ son los datos que  para comprobar si el modelo que hemos generado a partir de los datos de entrenamiento “funciona”. Es decir, si las respuestas predichas por el modelo para un caso totalmente nuevo son acertadas o no.\n",
    "\n",
    "Es importante que el conjunto de datos de prueba tenga un volumen suficiente como para generar resultados estadísticamente significativos, y a la vez, que sea representativo del conjunto de datos global.\n",
    "\n",
    "Normalmente el conjunto de datos se suele repartir en un 80% de datos de entrenamiento y un 20% de datos de test, pero se puede variar la proporción según el caso. Lo importante es ser siempre conscientes de que hay que evitar el sobreajuste u “overfitting”.\n",
    "\n",
    "### Sobreajuste (overfitting)\n",
    "\n",
    "El sobreajuste ocurre cuando un modelo está “sobre-entrenado”. Son modelos complejos que se ajusta tan milimétricamente al conjunto de datos a partir del cual se han creado, que pierden gran parte de su poder predictivo, y ya no son útiles para otros conjuntos de datos. Esto se debe a que los datos siempre tienen cierto grado de error o imprecisión, e intentar ajustarse demasiado a ellos, complica el modelo inútilmente al mismo tiempo que le resta utilidad. \n",
    "\n",
    "\n",
    "### Subajuste (underfitting)\n",
    "\n",
    "El underfitting o subajuste es justamente el caso contrario. Ocurre cuando el conjunto de datos de entrenamiento es insuficiente, con ruido en alguna de sus dimensiones o, en definitiva, poco representativo. Como consecuencia, nos lleva a un modelo excesivamente simple, con poco valor predictor. Por ello, para generar un buen modelo, es importante encontrar el punto medio entre ambas tendencias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC\n",
    "\n",
    "<img style=\"float: center;\" src=\"roc.png\" width=\"300\">\n",
    "\n",
    "Una curva ROC (receiver operating characteristic ) es un gráfico que muestra el rendimiento de un modelo de clasificación en todos los umbrales de clasificación. Esta curva representa dos parámetros:\n",
    "\n",
    "- Tasa de verdaderos positivos \n",
    "- Tasa de falsos positivos\n",
    "<img style=\"float: right;\" src=\"roc2.png\" width=\"300\">\n",
    "\n",
    "**Tasa de verdaderos positivos (TPR)** es sinónimo de exhaustividad y, por lo tanto, se define de la siguiente manera:\n",
    "\n",
    "$$TRP = \\frac{VP}{VP+FN}$$\n",
    "\n",
    "**Tasa de falsos positivos (FPR)** se define de la siguiente manera:\n",
    "$$TPR = \\frac{FP}{FP+VN}$$\n",
    "\n",
    "\n",
    "Una curva ROC representa TPR frente a FPR en diferentes umbrales de clasificación. Reducir el umbral de clasificación clasifica más elementos como positivos, por lo que aumentarán tanto los falsos positivos como los verdaderos positivos.\n",
    "\n",
    "\n",
    "\n",
    "Para calcular los puntos en una curva ROC, en teoría se debería evaluar el modelo de regresión logística muchas veces con diferentes umbrales de clasificación, pero esto es ineficiente. Afortunadamente, existe un algoritmo eficiente basado en ordenamiento que puede brindarnos esta información, denominado AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC: Área bajo la curva ROC\n",
    "\n",
    "<img style=\"float: right;\" src=\"auc.png\" width=\"300\">\n",
    "\n",
    "El AUC proporciona una medición agregada del rendimiento en todos los umbrales de clasificación posibles. Una forma de interpretar el AUC es como la probabilidad de que el modelo clasifique un ejemplo positivo aleatorio más alto que un ejemplo negativo aleatorio. Observa, a modo de ilustración, los siguientes ejemplos, que están ordenados de izquierda a derecha en orden ascendente con respecto a las predicciones de regresión logística:\n",
    "\n",
    "<img style=\"float:center;\" src=\"ejemplo.png\" width=\"500\">\n",
    "\n",
    "El AUC representa la probabilidad de que un ejemplo aleatorio positivo (verde) se posicione a la derecha de un ejemplo aleatorio negativo (rojo).\n",
    "\n",
    "El AUC oscila en valor del 0 al 1. Un modelo cuyas predicciones son un 100% incorrectas tiene un AUC de 0.0; otro cuyas predicciones son un 100% correctas tiene un AUC de 1.0.\n",
    "\n",
    "El AUC es conveniente por las dos razones siguientes:\n",
    "\n",
    "- El AUC es invariable con respecto a la escala. Mide qué tan bien se clasifican las predicciones, en lugar de sus valores absolutos.\n",
    "- El AUC es invariable con respecto al umbral de clasificación. Mide la calidad de las predicciones del modelo, sin tener en cuenta qué umbral de clasificación se elige.\n",
    "\n",
    "Sin embargo, estas dos razones tienen algunas advertencias, que pueden limitar la utilidad del AUC en determinados casos:\n",
    "\n",
    "- La invariabilidad de escala no siempre es conveniente. Por ejemplo, en algunas ocasiones, realmente necesitamos resultados de probabilidad bien calibrados, y el AUC no nos indicará eso.\n",
    "\n",
    "- La invariabilidad del umbral de clasificación no siempre es conveniente. En los casos en que hay amplias discrepancias en las consecuencias de los falsos negativos frente a los falsos positivos, es posible que sea fundamental minimizar un tipo de error de clasificación. Por ejemplo, al realizar la detección de spam de correo electrónico, es probable que quieras priorizar la minimización de los falsos positivos (aunque eso resulte en un aumento significativo de los falsos negativos). El AUC no es una métrica útil para este tipo de optimización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supuestos <a class=\"anchor\" id=\"supuestos\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de regresión logístico como tantísimos otros (casi absolutamente todos) modelos estadísticos, deberá cumplir una serie de supuestos que permitan concluir que el mismo es una buena versión simplificada de la información y, por tanto, tiene sentido usarlo para establecer dichas relaciones ded causación.m\n",
    "- Independencia: las observaciones tienen que ser independientes unas de otras.\n",
    "- Relación lineal entre el logaritmo natural de odds y la variable continua: \n",
    "<!--patrones en forma de U son una clara violación de esta condición.-->\n",
    "- La regresión logística no precisa de una distribución normal de la variable continua independiente.\n",
    "- Número de observaciones: no existe una norma establecida al respecto, pero se recomienda entre 50 a 100 observaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación de supuestos <a class=\"anchor\" id=\"validacion\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "x = rnorm(1000)\n",
    "eta = 4 + 2*x\n",
    "p = 1/(1 + exp(-eta))\n",
    "y = rbinom(n = 1000, size = 1, prob = p)\n",
    "base <- data.frame(y, x)\n",
    "head(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al haber simulado el modelo $\\text{log}\\left(\\frac{p}{1-p}\\right) = 4 + 2x_t$, ($\\beta_0=4, \\beta_1=2$ y $p=P(y=1)$), debe ser natural que el modelo ajustado sea similar, veamos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret) \n",
    "trainIndex <- createDataPartition(base$y,p=0.8,list=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- base[trainIndex, ]\n",
    "test <- base[-trainIndex, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(train)\n",
    "dim(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión lineal \n",
    "fit_lm  = lm(y ~ x, data = train)\n",
    "# Regresión logística\n",
    "fit_glm = glm(y ~ x, data = train, family = binomial(link = \"logit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(y ~ x, data = base, \n",
    "     pch = 20, ylab = \"Probabilida estimada\", \n",
    "     main = \"Regresión lineal vs logística\")\n",
    "grid()\n",
    "abline(fit_lm, col = \"darkorange\")\n",
    "curve(predict(fit_glm, data.frame(x), type = \"response\"), \n",
    "      add = TRUE, col = \"dodgerblue\", lty = 2)\n",
    "legend(\"topleft\", c(\"Lineal\", \"Logística\", \"Data\"), lty = c(1, 2, 0), \n",
    "       pch = c(NA, NA, 20), lwd = 2, col = c(\"darkorange\", \"dodgerblue\", \"black\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(fit_glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,2))\n",
    "plot(fit_glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pchisq(390.13 - 265.18, df=799-798, lower.tail=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anova(fit_glm,test = \"LRT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_link_scores <- predict(fit_glm, test, type=\"link\")\n",
    "glm_link_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glm_response_scores <- predict(fit_glm, test, type=\"response\")\n",
    "glm_response_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted.classes <- ifelse(glm_response_scores > 0.5, 1, 0)\n",
    "predicted.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test$y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(pROC)\n",
    "roc_info <- roc(test$y, predicted.classes, legacy.axes = TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(pty = \"s\") # square\n",
    "roc(test$y, predicted.classes, plot = TRUE, legacy.axes = TRUE,\n",
    "    percent = TRUE, xlab = \"Porcentaje Falsos positivos\",\n",
    "    ylab = \"Porcentaje verdaderos postivios\", col = \"#377eb8\", lwd = 2,\n",
    "    print.auc = TRUE, print.auc.x =45, partial.auc = c(100, 90), # en terminos de especificidad\n",
    "    auc.polygon.col = \"#377eb850\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Aplicación <a class=\"anchor\" id=\"ejemplo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dispone de un registro que contiene cientos de emails con información de cada uno de ellos. El objetivo de estudio es intentar crear un modelo que permita filtrar qué emails son “spam” y cuáles no, en función de determinadas características. Ejemplo extraído del libro OpenIntro Statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse) \n",
    "library(MASS)\n",
    "library(car)\n",
    "library(e1071)\n",
    "library(caret)\n",
    "library(cowplot)\n",
    "library(caTools)\n",
    "library(pROC)\n",
    "library(ggcorrplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "telco  = read.csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "telco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glimpse(telco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 6, repr.plot.height = 4)\n",
    "missing_data <- telco %>% summarise_all(funs(sum(is.na(.))/n()))\n",
    "missing_data <- gather(missing_data, key = \"variables\", value = \"percent_missing\")\n",
    "ggplot(missing_data, aes(x = reorder(variables, percent_missing), y = percent_missing)) +\n",
    "geom_bar(stat = \"identity\", fill = \"red\", aes(color = I('white')), size = 0.3)+\n",
    "xlab('variables')+\n",
    "coord_flip()+ \n",
    "theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Solo faltan 11 datos en el campo TotalCharges, así que elimine esas filas del conjunto de datos.\n",
    "- Hay tres variables continuas y son Tenure, MonthlyCharges y TotalCharges. SeniorCitizen está en forma 'int', que se puede cambiar a categórica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco <- telco[complete.cases(telco),]\n",
    "\n",
    "telco$SeniorCitizen <- as.factor(ifelse(telco$SeniorCitizen==1, 'YES', 'NO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme1 <- theme_bw()+\n",
    "theme(axis.text.x = element_text(angle = 0, hjust = 1, vjust = 0.5),legend.position=\"none\")\n",
    "theme2 <- theme_bw()+\n",
    "theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),legend.position=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 6, repr.plot.height = 4)\n",
    "telco %>% \n",
    "group_by(Churn) %>% \n",
    "summarise(Count = n())%>% \n",
    "mutate(percent = prop.table(Count)*100)%>%\n",
    "ggplot(aes(reorder(Churn, -percent), percent), fill = Churn)+\n",
    "geom_col(fill = c(\"#FC4E07\", \"#E7B800\"))+\n",
    "geom_text(aes(label = sprintf(\"%.2f%%\", percent)), hjust = 0.01,vjust = -0.5, size =3)+ \n",
    "theme_bw()+  \n",
    "xlab(\"Churn\") + \n",
    "ylab(\"Percent\")+\n",
    "ggtitle(\"Churn Percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna CHURN da cuenta de la cantidad de Clientes que se fueron durante el último mes. Alrededor del 26% de los clientes abandonaron la plataforma en el último mes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 8)\n",
    "plot_grid(ggplot(telco, aes(x=gender,fill=Churn))+ geom_bar()+ theme1, \n",
    "          ggplot(telco, aes(x=SeniorCitizen,fill=Churn))+ geom_bar(position = 'fill')+theme1,\n",
    "          ggplot(telco, aes(x=Partner,fill=Churn))+ geom_bar(position = 'fill')+theme1,\n",
    "          ggplot(telco, aes(x=Dependents,fill=Churn))+ geom_bar(position = 'fill')+theme1,\n",
    "          ggplot(telco, aes(x=PhoneService,fill=Churn))+ geom_bar(position = 'fill')+theme1,\n",
    "          ggplot(telco, aes(x=MultipleLines,fill=Churn))+ geom_bar(position = 'fill')+theme_bw()+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),\n",
    "          align = \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Género: el porcentaje de abandono es casi igual en el caso de hombres y mujeres\n",
    "- El porcentaje de abandono es mayor en el caso de las personas mayores\n",
    "- Los clientes con socios y dependientes tienen una tasa de abandono más baja en comparación con aquellos que no tienen socios y dependientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 8)\n",
    "plot_grid(ggplot(telco, aes(x=InternetService,fill=Churn))+ geom_bar(position = 'fill')+ theme1+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)), \n",
    "          ggplot(telco, aes(x=OnlineSecurity,fill=Churn))+ geom_bar(position = 'fill')+theme1+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),\n",
    "          ggplot(telco, aes(x=OnlineBackup,fill=Churn))+ geom_bar(position = 'fill')+theme1+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),\n",
    "          ggplot(telco, aes(x=DeviceProtection,fill=Churn))+ geom_bar(position = 'fill')+theme1+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),\n",
    "          ggplot(telco, aes(x=TechSupport,fill=Churn))+ geom_bar(position = 'fill')+theme1+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),\n",
    "          ggplot(telco, aes(x=StreamingTV,fill=Churn))+ geom_bar(position = 'fill')+theme_bw()+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),\n",
    "          align = \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La tasa de abandono es mucho mayor en el caso de los servicios de Internet de fibra óptica.\n",
    "- Los clientes que no tienen servicios como No OnlineSecurity, OnlineBackup y TechSupport abandonaron la plataforma el mes pasado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(ggplot(telco, aes(x=StreamingMovies,fill=Churn))+ \n",
    "          geom_bar(position = 'fill')+ theme1+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)), \n",
    "          ggplot(telco, aes(x=Contract,fill=Churn))+ \n",
    "          geom_bar(position = 'fill')+theme1+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),\n",
    "          ggplot(telco, aes(x=PaperlessBilling,fill=Churn))+ \n",
    "          geom_bar(position = 'fill')+theme1+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),\n",
    "          ggplot(telco, aes(x=PaymentMethod,fill=Churn))+\n",
    "          geom_bar(position = 'fill')+theme_bw()+\n",
    "          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),\n",
    "          align = \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Un porcentaje mayor de Clientes con suscripción mensual se ha ido en comparación con Clientes con contrato de uno o dos años.\n",
    "- El porcentaje de abandono es mayor en el caso de los clientes que tienen la opción de facturación electrónica.\n",
    "- Los clientes que tienen el método de pago ElectronicCheck tienden a abandonar la plataforma más en comparación con otras opciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width =10, repr.plot.height = 5)\n",
    "ggplot(telco, aes(y= tenure, x = \"\", fill = Churn)) + \n",
    "geom_boxplot()+ \n",
    "theme_bw()+\n",
    "xlab(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenure: La permanencia media de los clientes que se han ido es de unos 10 meses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(telco, aes(y= MonthlyCharges, x = \"\", fill = Churn)) + \n",
    "geom_boxplot()+ \n",
    "theme_bw()+\n",
    "xlab(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MonthlyCharges: Los clientes que se han ido tienen cargos mensuales elevados. La mediana está por encima de 75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(telco, aes(y= TotalCharges, x = \"\", fill = Churn)) + \n",
    "geom_boxplot()+ \n",
    "theme_bw()+\n",
    "xlab(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TotalCharges:* La mediana de los cargos totales de los clientes que han abandonado es baja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width =6, repr.plot.height = 4)\n",
    "telco_cor <- round(cor(telco[,c(\"tenure\", \"MonthlyCharges\", \"TotalCharges\")]), 1)\n",
    "\n",
    "ggcorrplot(telco_cor,  title = \"Correlation\")+theme(plot.title = element_text(hjust = 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datos \n",
    "\n",
    "Estandarizando valores diferentes en variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco <- data.frame(lapply(telco, function(x) {\n",
    "                  gsub(\"No internet service\", \"No\", x)}))\n",
    "\n",
    "telco <- data.frame(lapply(telco, function(x) {\n",
    "                  gsub(\"No phone service\", \"No\", x)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estandarizando variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns <- c(\"tenure\", \"MonthlyCharges\", \"TotalCharges\")\n",
    "telco[num_columns] <- sapply(telco[num_columns], as.numeric)\n",
    "\n",
    "telco_int <- telco[,c(\"tenure\", \"MonthlyCharges\", \"TotalCharges\")]\n",
    "telco_int <- data.frame(scale(telco_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificar la antigüedad por cliente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(telco$tenure)\n",
    "#min(telco$tenure)\n",
    "telco <- mutate(telco, tenure_bin = tenure)\n",
    "\n",
    "telco$tenure_bin[telco$tenure_bin >=0 & telco$tenure_bin <= 12] <- '0-1 y'\n",
    "telco$tenure_bin[telco$tenure_bin > 12 & telco$tenure_bin <= 24] <- '1-2 y'\n",
    "telco$tenure_bin[telco$tenure_bin > 24 & telco$tenure_bin <= 36] <- '2-3 y'\n",
    "telco$tenure_bin[telco$tenure_bin > 36 & telco$tenure_bin <= 48] <- '3-4 y'\n",
    "telco$tenure_bin[telco$tenure_bin > 48 & telco$tenure_bin <= 60] <- '4-5 y'\n",
    "telco$tenure_bin[telco$tenure_bin > 60 & telco$tenure_bin <= 72] <- '5-6 y'\n",
    "\n",
    "telco$tenure_bin <- as.factor(telco$tenure_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width =6, repr.plot.height = 3)\n",
    "ggplot(telco, aes(tenure_bin, fill = tenure_bin)) + geom_bar()+ theme1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_cat <- telco[,-c(1,6,19,20)]\n",
    "dummy<- data.frame(sapply(telco_cat,function(x) data.frame(model.matrix(~x-1,data =telco_cat))[,-1]))\n",
    "head(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "telco_final <- cbind(telco_int,dummy)\n",
    "head(telco_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición de la base de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "set.seed(123)\n",
    "indices = sample.split(telco_final$Churn, SplitRatio = 0.7)\n",
    "train = telco_final[indices,]\n",
    "test = telco_final[!(indices),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo saturado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_1 = glm(Churn ~ ., data = train, family = \"binomial\")\n",
    "summary(modelo_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pequeño atajo en lma búsqueda de un buen modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_2 <- stepAIC(modelo_1, direction=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(modelo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pchisq(5699.5-4143.1, df=4921-4904, lower.tail=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar el factor de inflación de la varianza (vif) para eliminar los predictores redundantes o las variables que tienen una alta multicolinealidad entre ellos. La multicolinealidad existe cuando dos o más variables predictoras están muy relacionadas entre sí y luego se vuelve difícil entender el impacto de una variable independiente sobre la variable dependiente.\n",
    "\n",
    "El factor de inflación de la varianza (VIF) se utiliza para medir la multicolinealidad entre las variables predictoras en un modelo. Un predictor que tiene un VIF de 2 o menos generalmente se considera seguro y se puede suponer que no está correlacionado con otras variables predictoras. Cuanto mayor sea el VIF, mayor es la correlación de la variable predictora con otras variables predictoras. Sin embargo, los predictores con un VIF alto pueden tener un valor p alto (o muy significativo), por lo tanto, necesitamos ver la importancia de la variable predictora antes de eliminarla de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vif(modelo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 <-glm(formula = Churn ~ tenure + MonthlyCharges + SeniorCitizen + \n",
    "    Partner + InternetService.xFiber.optic + InternetService.xNo + \n",
    "    OnlineSecurity + OnlineBackup + TechSupport + \n",
    "    StreamingTV + Contract.xOne.year + Contract.xTwo.year + PaperlessBilling + \n",
    "    PaymentMethod.xElectronic.check, family = \"binomial\", data = train)\n",
    "summary(model_3)\n",
    "vif(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model <- glm(formula = Churn ~ tenure + MonthlyCharges + SeniorCitizen + \n",
    "    Partner + InternetService.xFiber.optic + InternetService.xNo + \n",
    "    OnlineSecurity + OnlineBackup + TechSupport +  \n",
    "    Contract.xOne.year + Contract.xTwo.year + PaperlessBilling + \n",
    "    PaymentMethod.xElectronic.check, family = \"binomial\", data = train)\n",
    "\n",
    "summary(final_model)\n",
    "vif(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred <- predict(final_model, type = \"response\", newdata = test[,-24])\n",
    "summary(pred)\n",
    "test$prob <- pred\n",
    "\n",
    "# Usando 50% como punto de corte\n",
    "\n",
    "pred_churn <- factor(ifelse(pred >= 0.50, \"Yes\", \"No\"))\n",
    "actual_churn <- factor(ifelse(test$Churn==1,\"Yes\",\"No\"))\n",
    "table(actual_churn,pred_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_churn <- factor(ifelse(pred >=0.50, \"Yes\", \"No\"))\n",
    "conf_final <- confusionMatrix(cutoff_churn, actual_churn, positive = \"Yes\")\n",
    "accuracy <- conf_final$overall[1]\n",
    "sensitivity <- conf_final$byClass[1]\n",
    "specificity <- conf_final$byClass[2]\n",
    "accuracy\n",
    "sensitivity\n",
    "specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_fn <- function(cutoff) \n",
    "{\n",
    "  predicted_churn <- factor(ifelse(pred >= cutoff, \"Yes\", \"No\"))\n",
    "  conf <- confusionMatrix(predicted_churn, actual_churn, positive = \"Yes\")\n",
    "  accuray <- conf$overall[1]\n",
    "  sensitivity <- conf$byClass[1]\n",
    "  specificity <- conf$byClass[2]\n",
    "  out <- t(as.matrix(c(sensitivity, specificity, accuray))) \n",
    "  colnames(out) <- c(\"sensitivity\", \"specificity\", \"accuracy\")\n",
    "  return(out)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width =8, repr.plot.height =6)\n",
    "summary(pred)\n",
    "s = seq(0.01,0.80,length=100)\n",
    "OUT = matrix(0,100,3)\n",
    "\n",
    "for(i in 1:100)\n",
    "{\n",
    "  OUT[i,] = perform_fn(s[i])\n",
    "} \n",
    "\n",
    "plot(s, OUT[,1],xlab=\"Cutoff\",ylab=\"Valor\",cex.lab=1.5,cex.axis=1.5,ylim=c(0,1),\n",
    "     type=\"l\",lwd=2,axes=FALSE,col=2)\n",
    "axis(1,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)\n",
    "axis(2,seq(0,1,length=5),seq(0,1,length=5),cex.lab=1.5)\n",
    "lines(s,OUT[,2],col=\"darkgreen\",lwd=2)\n",
    "lines(s,OUT[,3],col=4,lwd=2)\n",
    "box()\n",
    "legend(\"bottom\",col=c(2,\"darkgreen\",4,\"darkred\"),text.font =3,inset = 0.02,\n",
    "       box.lty=0,cex = 0.8, \n",
    "       lwd=c(2,2,2,2),c(\"Sensitivity\",\"Specificity\",\"Accuracy\"))\n",
    "abline(v = 0.32, col=\"red\", lwd=1, lty=2)\n",
    "axis(1, at = seq(0.1, 1, by = 0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, curva ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm.roc <- roc(response = test$Churn, predictor = as.numeric(pred))\n",
    "plot(glm.roc,      legacy.axes = TRUE, print.auc.y = 1.0, print.auc = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
