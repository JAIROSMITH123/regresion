{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"img/logo.png\" width=\"500\">\n",
    "\n",
    "\n",
    "# Análisis de Regresión (2022-1)\n",
    "## Especialización en Estadística Aplicada\n",
    "#### Prof. [Sébastien Lozano Forero](https://www.linkedin.com/in/sebastienlozanoforero/) (slozanof@libertadores.edu.co)\n",
    "\n",
    "## <font color='red'>Ejemplos de Regresión Logística</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos para realizar el análisis\n",
    "temperatura <-c(66,70,69,68,67,72,73,70,57,63,70,78,67,53,67,75,70,81,76,79,75,76,58)\n",
    "defecto <-c( 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1)\n",
    "aux <-matrix(c(temperatura,defecto),ncol = 2)\n",
    "colnames(aux) <- c('temperatura','defecto')\n",
    "datos<-data.frame(aux)\n",
    "\n",
    "# Resumen de cuantos elementos hay de cada (tanto defectuosos como correctos)\n",
    "table(datos$defecto)\n",
    "##  0  1 \n",
    "## 18  5\n",
    "# Representar visualmente los datos\n",
    "colores <- NULL\n",
    "colores[datos$defecto == 0] <- \"green\"\n",
    "colores[datos$defecto == 1] <- \"red\"\n",
    "plot(datos$temperatura, datos$defecto, pch = 21, bg = colores, xlab = \"Temperatura\", ylab = \"Prob. defecto\")\n",
    "legend(\"bottomleft\", c(\"No defecto\", \"Si defecto\"), pch = 21, col = c(\"green\", \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el modelo de regresión lineal generalizado y parametrizamos por binomial\n",
    "reg <- glm(defecto ~ temperatura, data = datos, family = binomial)\n",
    "summary(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecimos la probabilidad de defectos y la insertamos en el dataframe como columna extra\n",
    "\n",
    "datos$Fallo <- predict(reg,datos,type=\"response\")\n",
    "\n",
    "#Tomamos la decisión de si será defectuosa la pieza en función a su probabilidad de defecto\n",
    "#Determinamos  que la pieza será defectuosa cuando haya una probabilidad de defectos superior al 50%\n",
    "datos$predic <- ifelse(datos$Fallo > 0.5,1,0)\n",
    "\n",
    "#Enfrentamos la predicción contra la realidad\n",
    "table(datos$predic,datos$defecto)\n",
    "\n",
    "#Predecimos si una pieza es buena o defectuosa para una temperatura de 60ºC\n",
    "\n",
    "Prob.def <- data.frame(temperatura=60)\n",
    "Prediccion <- predict(reg, Prob.def, type = \"response\")\n",
    "if (Prediccion >= 0.5) {\n",
    "  print(\"Pieza defectuosa\")\n",
    "}else{\n",
    "  print(\"Pieza buena\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 2\n",
    "\n",
    "Consideremos los datos adult.csv. Intentaremos predecir la variable de respuesta ABOVE50k (Salario >50k) mediante una regresión logística basada en variables demográficas explicativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData <- read.csv(\"http://idaejin.github.io/courses/R/data/adult.csv\")\n",
    "head(inputData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idealmente, la proporción de eventos y no eventos en la variable $Y$ debería ser aproximadamente la misma. Por lo tanto, primero verifiquemos la proporción de clases en la variable dependiente ABOVE50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(inputData$ABOVE50K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente, existe un sesgo de clase, una condición observada cuando la proporción de eventos es mucho menor que la proporción de no eventos. Por lo tanto, debemos muestrear las observaciones en proporciones aproximadamente iguales para obtener mejores modelos.\n",
    "\n",
    "Una manera de abordar el problema del sesgo de clase es muestrear los 0 y 1 para los trainingData (muestra de entrenamiento) en proporciones iguales. Al hacerlo, pondremos el resto de los inputData no incluidos para la formación en testData (muestra de validación). Como resultado, el tamaño de la muestra de entrenamiento será menor que el de la validación, lo que está bien, porque hay un gran número de observaciones (>10K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training Data\n",
    " input_ones <- inputData[which(inputData$ABOVE50K == 1), ]  # all 1's\n",
    "input_zeros <- inputData[which(inputData$ABOVE50K == 0), ]  # all 0's\n",
    "\n",
    "set.seed(100)  # for repeatability of samples\n",
    "\n",
    "input_ones_training_rows <- sample(1:nrow(input_ones), 0.7*nrow(input_ones))  # 1's for training\n",
    "input_zeros_training_rows <- sample(1:nrow(input_zeros), 0.7*nrow(input_ones))  # 0's for training. \n",
    "\n",
    "# Pick as many 0's as 1's\n",
    "training_ones <- input_ones[input_ones_training_rows, ]  \n",
    "training_zeros <- input_zeros[input_zeros_training_rows, ]\n",
    "trainingData <- rbind(training_ones, training_zeros)  # row bind the 1's and 0's \n",
    "\n",
    "# Create Test Data\n",
    " test_ones <- input_ones[-input_ones_training_rows, ]\n",
    "test_zeros <- input_zeros[-input_zeros_training_rows, ]\n",
    "\n",
    "testData <- rbind(test_ones, test_zeros)  # row bind the 1's and 0's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitMod <- glm(ABOVE50K ~ RELATIONSHIP + AGE + CAPITALGAIN + OCCUPATION + EDUCATIONNUM, data=trainingData, family=binomial(link=\"logit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted <- plogis(predict(logitMod, testData))  # predicted scores\n",
    "# or\n",
    "predicted <- predict(logitMod, testData, type=\"response\")  # predicted scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando usamos la función de predicción en este modelo, predecirá las probabilidades de la variable $Y$. Para convertirlo en una probabilidad de predicción que esté entre 0 y 1, usamos el plogis().\n",
    "\n",
    " \n",
    "\n",
    "Decidir la probabilidad de corte de predicción óptima para el modelo.\n",
    "\n",
    "El puntaje de probabilidad de la predicción de corte por defecto es de  \n",
    "0.5\n",
    "  o la proporción de 1’s y 0’s en los datos de entrenamiento. Pero a veces, afinar el corte de probabilidad puede mejorar la precisión tanto en las muestras de desarrollo como en las de validación. La función InformationValue::optimalCutoff proporciona formas de encontrar el punto de corte óptimo para mejorar la predicción de 1, 0, 1 y 0 y reducir el error de clasificación. Permite calcular la puntuación óptima que minimiza el error de clasificación para el modelo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"InformationValue\")\n",
    "library(InformationValue)\n",
    "optCutOff <- optimalCutoff(testData$ABOVE50K, predicted)[1] \n",
    "optCutOff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error de clasificación errónea es el desajuste porcentual de los valores predefinidos frente a los reales, independientemente de que sean 1 o 0. Cuanto menor sea el error de clasificación, mejor será su modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misClassError(testData$ABOVE50K, predicted, threshold = optCutOff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receiver Operating Characteristics a curva traza el porcentaje de verdaderos positivos pronosticados con precisión por un modelo logit dado a medida que la probabilidad de corte de la predicción se reduce de 1 a 0. Para un buen modelo, a medida que se reduce el corte, debería marcar más de 1 real como positivo y menos de 0 real como 1. Por lo tanto, para un buen modelo, la curva debería subir bruscamente, indicando que el TPR (eje Y) aumenta más rápido que el FPR (eje X) a medida que disminuye la puntuación de corte. Cuanto mayor sea el área bajo la curva ROC, mejor será la capacidad de predicción del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotROC(testData$ABOVE50K, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Sensibilidad (o Tasa Verdaderos Positivos) es el porcentaje de 1’s (reales) correctamente predichos por el modelo, mientras que, especificidad es el porcentaje de 0’s (reales) correctamente predicho. La especificidad también puede calcularse como 1-Tasa Falsos Positivos.\n",
    "\n",
    "\n",
    "$\\text{Sensibilidad}=\\frac{\\#\\text{1's predichos como 1's}}{\\# \\text{de 1's}}$\n",
    "\n",
    "$\\text{Especificidad}=\\frac{\\#\\text{0's predichos como 0's}}{\\# \\text{de  0's}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity(testData$ABOVE50K, predicted, threshold = optCutOff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity(testData$ABOVE50K, predicted, threshold = optCutOff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los números anteriores se calculan a partir de la muestra de validación que no se utilizó para la formación del modelo. Así que, una tasa de detección de la verdad de 34.42% en los datos de prueba es bueno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de Confusión Las columnas son reales, mientras que las filas son predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(testData$ABOVE50K, predicted, threshold = optCutOff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos es una colección de datos sobre algunos de los pasajeros, y el objetivo es predecir la supervivencia (1 si el pasajero sobrevivió o 0 si no lo hizo) basándose en algunas características como la clase de servicio, el sexo, la edad, etc. Como puede ver, vamos a utilizar variables categóricas y continuas (descripción de los datos [aquí](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3info.txt)\n",
    "\n",
    "Leemos los datos de entreamiento train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- read.csv('http://idaejin.github.io/courses/R/data/titanic_train.csv',header=TRUE,row.names=1)\n",
    " test <- read.csv('http://idaejin.github.io/courses/R/data/titanic_test.csv',header=TRUE,row.names=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desea\n",
    "- Ajustar un modelo logístico con pclass como variable explicativa. ¿Cuál es la interpretación del modelo ajustado?\n",
    "- Encontrar el mejor modelo de regresión logística posible basado en todas las variables disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- glm(Survived ~.,family=binomial(link='logit'),data=train)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova(model, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1 <- glm(Survived ~ as.factor(Pclass), family=binomial, data=train)\n",
    "summary(mod1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova(mod1,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "efecto de interacción entre la clase de pasajero y el sexo, ya que la clase de pasajero mostró una diferencia mucho mayor en la tasa de supervivencia entre las mujeres en comparación con los hombres (es decir, las mujeres de clase superior tenían muchas más probabilidades de sobrevivir que las mujeres de clase inferior, mientras que los hombres de primera clase tenían más probabilidades de sobrevivir que los hombres de segunda o tercera clase, pero no por el mismo margen que las mujeres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2 <- glm(Survived ~ Pclass + Sex  + Age + SibSp, family = binomial(logit), data = train)\n",
    "summary(mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anova(mod2,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3 <-  glm(Survived ~ Pclass + Sex + Pclass:Sex + Age + SibSp, family = binomial(logit), data = train)\n",
    "summary(mod3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova(mod3,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova(mod3,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los pasos anteriores, evaluamos brevemente el ajuste del modelo, ahora nos gustaría ver cómo lo está haciendo el modelo al predecir $y$ en un nuevo conjunto de datos. Estableciendo el parámetro type='response', R producirá probabilidades en la forma de $P(y=1|X)$. Nuestro límite de decisión será de 0.5\n",
    "\n",
    "\n",
    "Si $P(y=1|X)>0.5$  entonces $y=1$ en caso contrario $y=0$. Tener en cuenta que para algunas aplicaciones diferentes límites de decisión podría ser una mejor opción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted.results <- predict(mod3,newdata=test,type='response')\n",
    "fitted.results <- ifelse(fitted.results > 0.5,1,0)\n",
    "\n",
    "misClasificError <- mean(fitted.results != test$Survived)\n",
    "print(paste('Accuracy',1-misClasificError))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión de 0.8075 en el conjunto de test es un buen resultado. Sin embargo, hay que tener en cuenta que este resultado depende en cierta medida de la división manual de los datos que hice anteriormente, por lo tanto, si deseamos una puntuación más precisa, sería mejor realizar algún tipo de validación cruzada, como la validación cruzada k-fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluar la capacidad predictiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"ROCR\")\n",
    "library(ROCR)\n",
    "p <- predict(mod3, newdata=subset(test,select=c(2,3,4,5,6,7,8)), type=\"response\")\n",
    "pr <- ROCR::prediction(p, test$Survived)\n",
    "prf <- performance(pr, measure = \"tpr\", x.measure = \"fpr\")\n",
    "plot(prf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc <- performance(pr, measure = \"auc\")\n",
    "auc <- auc@y.values[[1]]\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
